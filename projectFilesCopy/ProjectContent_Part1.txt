--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\docker-compose.yml ---
version: "3.9"

services:
  postgres:
    image: postgres:15
    container_name: ocr_postgres
    environment:
      POSTGRES_USER: ocr_admin
      POSTGRES_PASSWORD: ocr_admin
      POSTGRES_DB: ocr_platform
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infrastructure/db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ocr_admin -d ocr_platform"]
      interval: 10s
      timeout: 5s
      retries: 5

  gateway:
    build:
      context: .
      dockerfile: gateway/Dockerfile
    container_name: ocr_gateway
    depends_on:
      postgres:
        condition: service_healthy
      user-service:
        condition: service_healthy
      document-service:
        condition: service_healthy
      broker-service:
        condition: service_healthy
    environment:
      SERVICE_NAME: gateway
      USER_SERVICE_URL: http://user-service:8001/api
      DOCUMENT_SERVICE_URL: http://document-service:8002/api
      BROKER_SERVICE_URL: http://broker-service:8003/api
      JWT_SECRET_KEY: supersecretjwt
      JWT_ACCESS_TTL_SECONDS: "900"
      JWT_REFRESH_TTL_SECONDS: "604800"
    ports:
      - "8000:8000"
    volumes:
      - ./shared/python:/app/shared
    healthcheck:
      test:
        - CMD-SHELL
        - python -c "import urllib.request,sys; urllib.request.urlopen('http://localhost:8000/api/health')"
      interval: 10s
      timeout: 5s
      retries: 5

  user-service:
    build:
      context: .
      dockerfile: services/user-service/Dockerfile
    container_name: ocr_user_service
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      SERVICE_NAME: user-service
      POSTGRES_DSN: postgresql+asyncpg://ocr_admin:ocr_admin@postgres:5432/ocr_platform
      JWT_SECRET_KEY: supersecretjwt
      ACCESS_TOKEN_TTL_SECONDS: "900"
      REFRESH_TOKEN_TTL_SECONDS: "604800"
    volumes:
      - ./shared/python:/app/shared
    healthcheck:
      test:
        - CMD-SHELL
        - python -c "import urllib.request,sys; urllib.request.urlopen('http://localhost:8001/api/health')"
      interval: 10s
      timeout: 5s
      retries: 5

  document-service:
    build:
      context: .
      dockerfile: services/document-service/Dockerfile
    container_name: ocr_document_service
    depends_on:
      postgres:
        condition: service_healthy
      broker-service:
        condition: service_healthy
    environment:
      SERVICE_NAME: document-service
      POSTGRES_DSN: postgresql+asyncpg://ocr_admin:ocr_admin@postgres:5432/ocr_platform
      BROKER_SERVICE_URL: http://broker-service:8003
      STORAGE_BACKEND: postgres
      MAX_UPLOAD_MB: "10"
    volumes:
      - ./shared/python:/app/shared
    healthcheck:
      test:
        - CMD-SHELL
        - python -c "import urllib.request,sys; urllib.request.urlopen('http://localhost:8002/api/health')"
      interval: 10s
      timeout: 5s
      retries: 5

  broker-service:
    build:
      context: .
      dockerfile: services/broker-service/Dockerfile
    container_name: ocr_broker_service
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      SERVICE_NAME: broker-service
      POSTGRES_DSN: postgresql+asyncpg://ocr_admin:ocr_admin@postgres:5432/ocr_platform
      VISIBILITY_TIMEOUT_SECONDS: "120"
      JOB_LEASE_SECONDS: "60"
      CLEANUP_INTERVAL_SECONDS: "30"
    volumes:
      - ./shared/python:/app/shared
    healthcheck:
      test:
        - CMD-SHELL
        - python -c "import urllib.request,sys; urllib.request.urlopen('http://localhost:8003/api/health')"
      interval: 10s
      timeout: 5s
      retries: 5

  image-preprocessing-service:
    build:
      context: .
      dockerfile: processing-services/image-preprocessing-service/Dockerfile
    container_name: ocr_preprocessing_service
    depends_on:
      broker-service:
        condition: service_healthy
      document-service:
        condition: service_healthy
    environment:
      SERVICE_NAME: image-preprocessing-service
      BROKER_SERVICE_URL: http://broker-service:8003
      DOCUMENT_SERVICE_URL: http://document-service:8002
      QUEUE_TOPIC: image_preprocess
    volumes:
      - ./shared/python:/app/shared

  ocr-service:
    build:
      context: .
      dockerfile: processing-services/ocr-service/Dockerfile
    container_name: ocr_ocr_service
    depends_on:
      broker-service:
        condition: service_healthy
      document-service:
        condition: service_healthy
    environment:
      SERVICE_NAME: ocr-service
      BROKER_SERVICE_URL: http://broker-service:8003
      DOCUMENT_SERVICE_URL: http://document-service:8002
      QUEUE_TOPIC: ocr_extract
      OCR_MODEL_NAME: microsoft/trocr-base-printed
    volumes:
      - ./shared/python:/app/shared

  worker-service:
    build:
      context: .
      dockerfile: services/worker-service/Dockerfile
    container_name: ocr_worker_service
    depends_on:
      broker-service:
        condition: service_healthy
      document-service:
        condition: service_healthy
    environment:
      SERVICE_NAME: worker-service
      BROKER_SERVICE_URL: http://broker-service:8003
      DOCUMENT_SERVICE_URL: http://document-service:8002
      DOCUMENT_EVENTS_TOPIC: document_events
      PREPROCESS_TOPIC: image_preprocess
      OCR_TOPIC: ocr_extract
    volumes:
      - ./shared/python:/app/shared

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
      args:
        VITE_API_BASE_URL: ${VITE_API_BASE_URL:-http://localhost:8000}
    container_name: ocr_frontend
    depends_on:
      gateway:
        condition: service_healthy
    ports:
      - "5173:5173"

volumes:
  postgres_data:

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\docker-compose.yml ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\README.md ---
# OCR Microservices Platform

An asynchronous optical character recognition platform built with a modular microservices architecture. Users can upload images, trigger background OCR pipelines, and inspect extracted text via a unified web UI.

## Service Overview

- **Frontend**: SPA served with Vite, communicates only with the API Gateway.
- **API Gateway**: FastAPI service acting as single entry point. Handles authentication, request routing, rate limiting, and response aggregation.
- **User Service**: Manages accounts, hashed credentials, refresh tokens, and JWT claims.
- **Document Service**: Stores original images, preprocessing variants, and OCR outputs. Coordinates job state transitions.
- **Custom Message Broker**: Lightweight Python service offering REST-based enqueue/claim/ack endpoints backed by PostgreSQL persistence.
- **Image Preprocessing Service**: Applies deskewing, denoising, grayscale, and sharpening before OCR.
- **OCR Service**: Runs Hugging Face English OCR transformer models to extract text from processed images.
- **Worker Service**: Orchestrates multi-step pipelines, translating document events into broker tasks.

## Infrastructure

- **PostgreSQL**: Primary data store for users, documents, and broker queues.
- **Docker Compose**: Containers orchestrated for local development; each service ships with its own Dockerfile.

---

Refer to `docs/architecture.md` for diagrams and detailed message flows once available.

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\README.md ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\Dockerfile ---
FROM node:20-alpine AS builder

WORKDIR /app

ARG VITE_API_BASE_URL
ENV VITE_API_BASE_URL=${VITE_API_BASE_URL}

COPY frontend/package*.json ./
RUN npm install

COPY frontend/ ./
RUN npm run build

FROM node:20-alpine
WORKDIR /app

COPY --from=builder /app/package*.json ./
RUN npm install

COPY --from=builder /app/vite.config.js ./vite.config.js
COPY --from=builder /app/dist ./dist

EXPOSE 5173
CMD ["npx", "vite", "preview", "--host", "0.0.0.0", "--port", "5173"]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\Dockerfile ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\index.html ---
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>OCR Platform</title>
  </head>
  <body>
    <div id="app"></div>
    <script type="module" src="/src/index.js"></script>
  </body>
</html>

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\index.html ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\package-lock.json ---
{
  "name": "ocr-frontend",
  "version": "0.1.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "ocr-frontend",
      "version": "0.1.0",
      "dependencies": {
        "axios": "^1.12.2"
      },
      "devDependencies": {
        "vite": "^5.4.21"
      }
    },
    "node_modules/@esbuild/aix-ppc64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/aix-ppc64/-/aix-ppc64-0.21.5.tgz",
      "integrity": "sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "aix"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/android-arm": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm/-/android-arm-0.21.5.tgz",
      "integrity": "sha512-vCPvzSjpPHEi1siZdlvAlsPxXl7WbOVUBBAowWug4rJHb68Ox8KualB+1ocNvT5fjv6wpkX6o/iEpbDrf68zcg==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/android-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm64/-/android-arm64-0.21.5.tgz",
      "integrity": "sha512-c0uX9VAUBQ7dTDCjq+wdyGLowMdtR/GoC2U5IYk/7D1H1JYC0qseD7+11iMP2mRLN9RcCMRcjC4YMclCzGwS/A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/android-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/android-x64/-/android-x64-0.21.5.tgz",
      "integrity": "sha512-D7aPRUUNHRBwHxzxRvp856rjUHRFW1SdQATKXH2hqA0kAZb1hKmi02OpYRacl0TxIGz/ZmXWlbZgjwWYaCakTA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/darwin-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-arm64/-/darwin-arm64-0.21.5.tgz",
      "integrity": "sha512-DwqXqZyuk5AiWWf3UfLiRDJ5EDd49zg6O9wclZ7kUMv2WRFr4HKjXp/5t8JZ11QbQfUS6/cRCKGwYhtNAY88kQ==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/darwin-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-x64/-/darwin-x64-0.21.5.tgz",
      "integrity": "sha512-se/JjF8NlmKVG4kNIuyWMV/22ZaerB+qaSi5MdrXtd6R08kvs2qCN4C09miupktDitvh8jRFflwGFBQcxZRjbw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/freebsd-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-arm64/-/freebsd-arm64-0.21.5.tgz",
      "integrity": "sha512-5JcRxxRDUJLX8JXp/wcBCy3pENnCgBR9bN6JsY4OmhfUtIHe3ZW0mawA7+RDAcMLrMIZaf03NlQiX9DGyB8h4g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/freebsd-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-x64/-/freebsd-x64-0.21.5.tgz",
      "integrity": "sha512-J95kNBj1zkbMXtHVH29bBriQygMXqoVQOQYA+ISs0/2l3T9/kj42ow2mpqerRBxDJnmkUDCaQT/dfNXWX/ZZCQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-arm": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm/-/linux-arm-0.21.5.tgz",
      "integrity": "sha512-bPb5AHZtbeNGjCKVZ9UGqGwo8EUu4cLq68E95A53KlxAPRmUyYv2D6F0uUI65XisGOL1hBP5mTronbgo+0bFcA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm64/-/linux-arm64-0.21.5.tgz",
      "integrity": "sha512-ibKvmyYzKsBeX8d8I7MH/TMfWDXBF3db4qM6sy+7re0YXya+K1cem3on9XgdT2EQGMu4hQyZhan7TeQ8XkGp4Q==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-ia32": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ia32/-/linux-ia32-0.21.5.tgz",
      "integrity": "sha512-YvjXDqLRqPDl2dvRODYmmhz4rPeVKYvppfGYKSNGdyZkA01046pLWyRKKI3ax8fbJoK5QbxblURkwK/MWY18Tg==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-loong64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-loong64/-/linux-loong64-0.21.5.tgz",
      "integrity": "sha512-uHf1BmMG8qEvzdrzAqg2SIG/02+4/DHB6a9Kbya0XDvwDEKCoC8ZRWI5JJvNdUjtciBGFQ5PuBlpEOXQj+JQSg==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-mips64el": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-mips64el/-/linux-mips64el-0.21.5.tgz",
      "integrity": "sha512-IajOmO+KJK23bj52dFSNCMsz1QP1DqM6cwLUv3W1QwyxkyIWecfafnI555fvSGqEKwjMXVLokcV5ygHW5b3Jbg==",
      "cpu": [
        "mips64el"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-ppc64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ppc64/-/linux-ppc64-0.21.5.tgz",
      "integrity": "sha512-1hHV/Z4OEfMwpLO8rp7CvlhBDnjsC3CttJXIhBi+5Aj5r+MBvy4egg7wCbe//hSsT+RvDAG7s81tAvpL2XAE4w==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-riscv64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-riscv64/-/linux-riscv64-0.21.5.tgz",
      "integrity": "sha512-2HdXDMd9GMgTGrPWnJzP2ALSokE/0O5HhTUvWIbD3YdjME8JwvSCnNGBnTThKGEB91OZhzrJ4qIIxk/SBmyDDA==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-s390x": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-s390x/-/linux-s390x-0.21.5.tgz",
      "integrity": "sha512-zus5sxzqBJD3eXxwvjN1yQkRepANgxE9lgOW2qLnmr8ikMTphkjgXu1HR01K4FJg8h1kEEDAqDcZQtbrRnB41A==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/linux-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-x64/-/linux-x64-0.21.5.tgz",
      "integrity": "sha512-1rYdTpyv03iycF1+BhzrzQJCdOuAOtaqHTWJZCWvijKD2N5Xu0TtVC8/+1faWqcP9iBCWOmjmhoH94dH82BxPQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/netbsd-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/netbsd-x64/-/netbsd-x64-0.21.5.tgz",
      "integrity": "sha512-Woi2MXzXjMULccIwMnLciyZH4nCIMpWQAs049KEeMvOcNADVxo0UBIQPfSmxB3CWKedngg7sWZdLvLczpe0tLg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "netbsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/openbsd-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/openbsd-x64/-/openbsd-x64-0.21.5.tgz",
      "integrity": "sha512-HLNNw99xsvx12lFBUwoT8EVCsSvRNDVxNpjZ7bPn947b8gJPzeHWyNVhFsaerc0n3TsbOINvRP2byTZ5LKezow==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/sunos-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/sunos-x64/-/sunos-x64-0.21.5.tgz",
      "integrity": "sha512-6+gjmFpfy0BHU5Tpptkuh8+uw3mnrvgs+dSPQXQOv3ekbordwnzTVEb4qnIvQcYXq6gzkyTnoZ9dZG+D4garKg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "sunos"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/win32-arm64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-arm64/-/win32-arm64-0.21.5.tgz",
      "integrity": "sha512-Z0gOTd75VvXqyq7nsl93zwahcTROgqvuAcYDUr+vOv8uHhNSKROyU961kgtCD1e95IqPKSQKH7tBTslnS3tA8A==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/win32-ia32": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-ia32/-/win32-ia32-0.21.5.tgz",
      "integrity": "sha512-SWXFF1CL2RVNMaVs+BBClwtfZSvDgtL//G/smwAc5oVK/UPu2Gu9tIaRgFmYFFKrmg3SyAjSrElf0TiJ1v8fYA==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@esbuild/win32-x64": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-x64/-/win32-x64-0.21.5.tgz",
      "integrity": "sha512-tQd/1efJuzPC6rCFwEvLtci/xNFcTZknmXs98FYDfGE4wP9ClFV98nyKrzJKVPMhdDnjzLhdUyMX4PsQAPjwIw==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@rollup/rollup-android-arm-eabi": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm-eabi/-/rollup-android-arm-eabi-4.52.5.tgz",
      "integrity": "sha512-8c1vW4ocv3UOMp9K+gToY5zL2XiiVw3k7f1ksf4yO1FlDFQ1C2u72iACFnSOceJFsWskc2WZNqeRhFRPzv+wtQ==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-android-arm64": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-android-arm64/-/rollup-android-arm64-4.52.5.tgz",
      "integrity": "sha512-mQGfsIEFcu21mvqkEKKu2dYmtuSZOBMmAl5CFlPGLY94Vlcm+zWApK7F/eocsNzp8tKmbeBP8yXyAbx0XHsFNA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ]
    },
    "node_modules/@rollup/rollup-darwin-arm64": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-arm64/-/rollup-darwin-arm64-4.52.5.tgz",
      "integrity": "sha512-takF3CR71mCAGA+v794QUZ0b6ZSrgJkArC+gUiG6LB6TQty9T0Mqh3m2ImRBOxS2IeYBo4lKWIieSvnEk2OQWA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-darwin-x64": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-darwin-x64/-/rollup-darwin-x64-4.52.5.tgz",
      "integrity": "sha512-W901Pla8Ya95WpxDn//VF9K9u2JbocwV/v75TE0YIHNTbhqUTv9w4VuQ9MaWlNOkkEfFwkdNhXgcLqPSmHy0fA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ]
    },
    "node_modules/@rollup/rollup-freebsd-arm64": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-freebsd-arm64/-/rollup-freebsd-arm64-4.52.5.tgz",
      "integrity": "sha512-QofO7i7JycsYOWxe0GFqhLmF6l1TqBswJMvICnRUjqCx8b47MTo46W8AoeQwiokAx3zVryVnxtBMcGcnX12LvA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@rollup/rollup-freebsd-x64": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-freebsd-x64/-/rollup-freebsd-x64-4.52.5.tgz",
      "integrity": "sha512-jr21b/99ew8ujZubPo9skbrItHEIE50WdV86cdSoRkKtmWa+DDr6fu2c/xyRT0F/WazZpam6kk7IHBerSL7LDQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-gnueabihf": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-gnueabihf/-/rollup-linux-arm-gnueabihf-4.52.5.tgz",
      "integrity": "sha512-PsNAbcyv9CcecAUagQefwX8fQn9LQ4nZkpDboBOttmyffnInRy8R8dSg6hxxl2Re5QhHBf6FYIDhIj5v982ATQ==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm-musleabihf": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm-musleabihf/-/rollup-linux-arm-musleabihf-4.52.5.tgz",
      "integrity": "sha512-Fw4tysRutyQc/wwkmcyoqFtJhh0u31K+Q6jYjeicsGJJ7bbEq8LwPWV/w0cnzOqR2m694/Af6hpFayLJZkG2VQ==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-gnu": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-gnu/-/rollup-linux-arm64-gnu-4.52.5.tgz",
      "integrity": "sha512-a+3wVnAYdQClOTlyapKmyI6BLPAFYs0JM8HRpgYZQO02rMR09ZcV9LbQB+NL6sljzG38869YqThrRnfPMCDtZg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-arm64-musl": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-arm64-musl/-/rollup-linux-arm64-musl-4.52.5.tgz",
      "integrity": "sha512-AvttBOMwO9Pcuuf7m9PkC1PUIKsfaAJ4AYhy944qeTJgQOqJYJ9oVl2nYgY7Rk0mkbsuOpCAYSs6wLYB2Xiw0Q==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-loong64-gnu": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-loong64-gnu/-/rollup-linux-loong64-gnu-4.52.5.tgz",
      "integrity": "sha512-DkDk8pmXQV2wVrF6oq5tONK6UHLz/XcEVow4JTTerdeV1uqPeHxwcg7aFsfnSm9L+OO8WJsWotKM2JJPMWrQtA==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-ppc64-gnu": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-ppc64-gnu/-/rollup-linux-ppc64-gnu-4.52.5.tgz",
      "integrity": "sha512-W/b9ZN/U9+hPQVvlGwjzi+Wy4xdoH2I8EjaCkMvzpI7wJUs8sWJ03Rq96jRnHkSrcHTpQe8h5Tg3ZzUPGauvAw==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-riscv64-gnu": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-riscv64-gnu/-/rollup-linux-riscv64-gnu-4.52.5.tgz",
      "integrity": "sha512-sjQLr9BW7R/ZiXnQiWPkErNfLMkkWIoCz7YMn27HldKsADEKa5WYdobaa1hmN6slu9oWQbB6/jFpJ+P2IkVrmw==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-riscv64-musl": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-riscv64-musl/-/rollup-linux-riscv64-musl-4.52.5.tgz",
      "integrity": "sha512-hq3jU/kGyjXWTvAh2awn8oHroCbrPm8JqM7RUpKjalIRWWXE01CQOf/tUNWNHjmbMHg/hmNCwc/Pz3k1T/j/Lg==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-s390x-gnu": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-s390x-gnu/-/rollup-linux-s390x-gnu-4.52.5.tgz",
      "integrity": "sha512-gn8kHOrku8D4NGHMK1Y7NA7INQTRdVOntt1OCYypZPRt6skGbddska44K8iocdpxHTMMNui5oH4elPH4QOLrFQ==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-gnu": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-gnu/-/rollup-linux-x64-gnu-4.52.5.tgz",
      "integrity": "sha512-hXGLYpdhiNElzN770+H2nlx+jRog8TyynpTVzdlc6bndktjKWyZyiCsuDAlpd+j+W+WNqfcyAWz9HxxIGfZm1Q==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-linux-x64-musl": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-linux-x64-musl/-/rollup-linux-x64-musl-4.52.5.tgz",
      "integrity": "sha512-arCGIcuNKjBoKAXD+y7XomR9gY6Mw7HnFBv5Rw7wQRvwYLR7gBAgV7Mb2QTyjXfTveBNFAtPt46/36vV9STLNg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ]
    },
    "node_modules/@rollup/rollup-openharmony-arm64": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-openharmony-arm64/-/rollup-openharmony-arm64-4.52.5.tgz",
      "integrity": "sha512-QoFqB6+/9Rly/RiPjaomPLmR/13cgkIGfA40LHly9zcH1S0bN2HVFYk3a1eAyHQyjs3ZJYlXvIGtcCs5tko9Cw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openharmony"
      ]
    },
    "node_modules/@rollup/rollup-win32-arm64-msvc": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-arm64-msvc/-/rollup-win32-arm64-msvc-4.52.5.tgz",
      "integrity": "sha512-w0cDWVR6MlTstla1cIfOGyl8+qb93FlAVutcor14Gf5Md5ap5ySfQ7R9S/NjNaMLSFdUnKGEasmVnu3lCMqB7w==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-ia32-msvc": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-ia32-msvc/-/rollup-win32-ia32-msvc-4.52.5.tgz",
      "integrity": "sha512-Aufdpzp7DpOTULJCuvzqcItSGDH73pF3ko/f+ckJhxQyHtp67rHw3HMNxoIdDMUITJESNE6a8uh4Lo4SLouOUg==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-x64-gnu": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-x64-gnu/-/rollup-win32-x64-gnu-4.52.5.tgz",
      "integrity": "sha512-UGBUGPFp1vkj6p8wCRraqNhqwX/4kNQPS57BCFc8wYh0g94iVIW33wJtQAx3G7vrjjNtRaxiMUylM0ktp/TRSQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@rollup/rollup-win32-x64-msvc": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/@rollup/rollup-win32-x64-msvc/-/rollup-win32-x64-msvc-4.52.5.tgz",
      "integrity": "sha512-TAcgQh2sSkykPRWLrdyy2AiceMckNf5loITqXxFI5VuQjS5tSuw3WlwdN8qv8vzjLAUTvYaH/mVjSFpbkFbpTg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ]
    },
    "node_modules/@types/estree": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/@types/estree/-/estree-1.0.8.tgz",
      "integrity": "sha512-dWHzHa2WqEXI/O1E9OjrocMTKJl2mSrEolh1Iomrv6U+JuNwaHXsXx9bLu5gG7BUWFIN0skIQJQ/L1rIex4X6w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/asynckit": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/asynckit/-/asynckit-0.4.0.tgz",
      "integrity": "sha512-Oei9OH4tRh0YqU3GxhX79dM/mwVgvbZJaSNaRk+bshkj0S5cfHcgYakreBjrHwatXKbz+IoIdYLxrKim2MjW0Q==",
      "license": "MIT"
    },
    "node_modules/axios": {
      "version": "1.12.2",
      "resolved": "https://registry.npmjs.org/axios/-/axios-1.12.2.tgz",
      "integrity": "sha512-vMJzPewAlRyOgxV2dU0Cuz2O8zzzx9VYtbJOaBgXFeLc4IV/Eg50n4LowmehOOR61S8ZMpc2K5Sa7g6A4jfkUw==",
      "license": "MIT",
      "dependencies": {
        "follow-redirects": "^1.15.6",
        "form-data": "^4.0.4",
        "proxy-from-env": "^1.1.0"
      }
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/combined-stream": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/combined-stream/-/combined-stream-1.0.8.tgz",
      "integrity": "sha512-FQN4MRfuJeHf7cBbBMJFXhKSDq+2kAArBlmRBvcvFE5BB1HZKXtSFASDhdlz9zOYwxh8lDdnvmMOe/+5cdoEdg==",
      "license": "MIT",
      "dependencies": {
        "delayed-stream": "~1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/delayed-stream": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/delayed-stream/-/delayed-stream-1.0.0.tgz",
      "integrity": "sha512-ZySD7Nf91aLB0RxL4KGrKHBXl7Eds1DAmEdcoVawXnLD7SDhpNgtuII2aAkg7a7QS41jxPSZ17p4VdGnMHk3MQ==",
      "license": "MIT",
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-set-tostringtag": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.1.0.tgz",
      "integrity": "sha512-j6vWzfrGVfyXxge+O0x5sh6cvxAog0a/4Rdd2K36zCMV5eJ+/+tOAngRO8cODMNWbVRdVlmGZQL2YS3yR8bIUA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/esbuild": {
      "version": "0.21.5",
      "resolved": "https://registry.npmjs.org/esbuild/-/esbuild-0.21.5.tgz",
      "integrity": "sha512-mg3OPMV4hXywwpoDxu3Qda5xCKQi+vCTZq8S9J/EpkhB2HzKXq4SNFZE3+NK93JYxc8VMSep+lOUSC/RVKaBqw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "bin": {
        "esbuild": "bin/esbuild"
      },
      "engines": {
        "node": ">=12"
      },
      "optionalDependencies": {
        "@esbuild/aix-ppc64": "0.21.5",
        "@esbuild/android-arm": "0.21.5",
        "@esbuild/android-arm64": "0.21.5",
        "@esbuild/android-x64": "0.21.5",
        "@esbuild/darwin-arm64": "0.21.5",
        "@esbuild/darwin-x64": "0.21.5",
        "@esbuild/freebsd-arm64": "0.21.5",
        "@esbuild/freebsd-x64": "0.21.5",
        "@esbuild/linux-arm": "0.21.5",
        "@esbuild/linux-arm64": "0.21.5",
        "@esbuild/linux-ia32": "0.21.5",
        "@esbuild/linux-loong64": "0.21.5",
        "@esbuild/linux-mips64el": "0.21.5",
        "@esbuild/linux-ppc64": "0.21.5",
        "@esbuild/linux-riscv64": "0.21.5",
        "@esbuild/linux-s390x": "0.21.5",
        "@esbuild/linux-x64": "0.21.5",
        "@esbuild/netbsd-x64": "0.21.5",
        "@esbuild/openbsd-x64": "0.21.5",
        "@esbuild/sunos-x64": "0.21.5",
        "@esbuild/win32-arm64": "0.21.5",
        "@esbuild/win32-ia32": "0.21.5",
        "@esbuild/win32-x64": "0.21.5"
      }
    },
    "node_modules/follow-redirects": {
      "version": "1.15.11",
      "resolved": "https://registry.npmjs.org/follow-redirects/-/follow-redirects-1.15.11.tgz",
      "integrity": "sha512-deG2P0JfjrTxl50XGCDyfI97ZGVCxIpfKYmfyrQ54n5FO/0gfIES8C/Psl6kWVDolizcaaxZJnTS0QSMxvnsBQ==",
      "funding": [
        {
          "type": "individual",
          "url": "https://github.com/sponsors/RubenVerborgh"
        }
      ],
      "license": "MIT",
      "engines": {
        "node": ">=4.0"
      },
      "peerDependenciesMeta": {
        "debug": {
          "optional": true
        }
      }
    },
    "node_modules/form-data": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/form-data/-/form-data-4.0.4.tgz",
      "integrity": "sha512-KrGhL9Q4zjj0kiUt5OO4Mr/A/jlI2jDYs5eHBpYHPcBEVSiipAvn2Ko2HnPe20rmcuuvMHNdZFp+4IlGTMF0Ow==",
      "license": "MIT",
      "dependencies": {
        "asynckit": "^0.4.0",
        "combined-stream": "^1.0.8",
        "es-set-tostringtag": "^2.1.0",
        "hasown": "^2.0.2",
        "mime-types": "^2.1.12"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz",
      "integrity": "sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==",
      "license": "MIT",
      "dependencies": {
        "has-symbols": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/mime-db": {
      "version": "1.52.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz",
      "integrity": "sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types": {
      "version": "2.1.35",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz",
      "integrity": "sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==",
      "license": "MIT",
      "dependencies": {
        "mime-db": "1.52.0"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/nanoid": {
      "version": "3.3.11",
      "resolved": "https://registry.npmjs.org/nanoid/-/nanoid-3.3.11.tgz",
      "integrity": "sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "bin": {
        "nanoid": "bin/nanoid.cjs"
      },
      "engines": {
        "node": "^10 || ^12 || ^13.7 || ^14 || >=15.0.1"
      }
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/postcss": {
      "version": "8.5.6",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.5.6.tgz",
      "integrity": "sha512-3Ybi1tAuwAP9s0r1UQ2J4n5Y0G05bJkpUIO0/bI9MhwmD70S5aTWbXGBwxHrelT+XM1k6dM0pk+SwNkpTRN7Pg==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.11",
        "picocolors": "^1.1.1",
        "source-map-js": "^1.2.1"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/proxy-from-env": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/proxy-from-env/-/proxy-from-env-1.1.0.tgz",
      "integrity": "sha512-D+zkORCbA9f1tdWRK0RaCR3GPv50cMxcrz4X8k5LTSUD1Dkw47mKJEZQNunItRTkWwgtaUSo1RVFRIG9ZXiFYg==",
      "license": "MIT"
    },
    "node_modules/rollup": {
      "version": "4.52.5",
      "resolved": "https://registry.npmjs.org/rollup/-/rollup-4.52.5.tgz",
      "integrity": "sha512-3GuObel8h7Kqdjt0gxkEzaifHTqLVW56Y/bjN7PSQtkKr0w3V/QYSdt6QWYtd7A1xUtYQigtdUfgj1RvWVtorw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/estree": "1.0.8"
      },
      "bin": {
        "rollup": "dist/bin/rollup"
      },
      "engines": {
        "node": ">=18.0.0",
        "npm": ">=8.0.0"
      },
      "optionalDependencies": {
        "@rollup/rollup-android-arm-eabi": "4.52.5",
        "@rollup/rollup-android-arm64": "4.52.5",
        "@rollup/rollup-darwin-arm64": "4.52.5",
        "@rollup/rollup-darwin-x64": "4.52.5",
        "@rollup/rollup-freebsd-arm64": "4.52.5",
        "@rollup/rollup-freebsd-x64": "4.52.5",
        "@rollup/rollup-linux-arm-gnueabihf": "4.52.5",
        "@rollup/rollup-linux-arm-musleabihf": "4.52.5",
        "@rollup/rollup-linux-arm64-gnu": "4.52.5",
        "@rollup/rollup-linux-arm64-musl": "4.52.5",
        "@rollup/rollup-linux-loong64-gnu": "4.52.5",
        "@rollup/rollup-linux-ppc64-gnu": "4.52.5",
        "@rollup/rollup-linux-riscv64-gnu": "4.52.5",
        "@rollup/rollup-linux-riscv64-musl": "4.52.5",
        "@rollup/rollup-linux-s390x-gnu": "4.52.5",
        "@rollup/rollup-linux-x64-gnu": "4.52.5",
        "@rollup/rollup-linux-x64-musl": "4.52.5",
        "@rollup/rollup-openharmony-arm64": "4.52.5",
        "@rollup/rollup-win32-arm64-msvc": "4.52.5",
        "@rollup/rollup-win32-ia32-msvc": "4.52.5",
        "@rollup/rollup-win32-x64-gnu": "4.52.5",
        "@rollup/rollup-win32-x64-msvc": "4.52.5",
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/source-map-js": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.1.tgz",
      "integrity": "sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/vite": {
      "version": "5.4.21",
      "resolved": "https://registry.npmjs.org/vite/-/vite-5.4.21.tgz",
      "integrity": "sha512-o5a9xKjbtuhY6Bi5S3+HvbRERmouabWbyUcpXXUA1u+GNUKoROi9byOJ8M0nHbHYHkYICiMlqxkg1KkYmm25Sw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "esbuild": "^0.21.3",
        "postcss": "^8.4.43",
        "rollup": "^4.20.0"
      },
      "bin": {
        "vite": "bin/vite.js"
      },
      "engines": {
        "node": "^18.0.0 || >=20.0.0"
      },
      "funding": {
        "url": "https://github.com/vitejs/vite?sponsor=1"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.3"
      },
      "peerDependencies": {
        "@types/node": "^18.0.0 || >=20.0.0",
        "less": "*",
        "lightningcss": "^1.21.0",
        "sass": "*",
        "sass-embedded": "*",
        "stylus": "*",
        "sugarss": "*",
        "terser": "^5.4.0"
      },
      "peerDependenciesMeta": {
        "@types/node": {
          "optional": true
        },
        "less": {
          "optional": true
        },
        "lightningcss": {
          "optional": true
        },
        "sass": {
          "optional": true
        },
        "sass-embedded": {
          "optional": true
        },
        "stylus": {
          "optional": true
        },
        "sugarss": {
          "optional": true
        },
        "terser": {
          "optional": true
        }
      }
    }
  }
}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\package-lock.json ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\package.json ---
{
  "name": "ocr-frontend",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview --port 5173"
  },
  "dependencies": {
    "axios": "^1.12.2"
  },
  "devDependencies": {
    "vite": "^5.4.21"
  }
}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\package.json ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\vite.config.js ---
import { defineConfig } from "vite";

export default defineConfig({
  server: {
    port: 5173,
    host: "0.0.0.0",
  },
  preview: {
    port: 5173,
    host: "0.0.0.0",
  },
});

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\vite.config.js ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\public\index.html ---
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>OCR Platform</title>
  </head>
  <body>
    <div id="app"></div>
    <script type="module" src="/src/index.js"></script>
  </body>
</html>

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\public\index.html ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\index.js ---
import "./styles/main.css";
import { createApp } from "./components/App";

document.addEventListener("DOMContentLoaded", () => {
  const appRoot = document.getElementById("app");
  if (!appRoot) {
    throw new Error("Missing root element");
  }
  appRoot.appendChild(createApp());
});

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\index.js ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\api\client.js ---
const runtimeOrigin =
  typeof window !== "undefined"
    ? `${window.location.protocol}//${window.location.hostname}:8000`
    : "http://localhost:8000";

const rawBaseUrl = import.meta.env.VITE_API_BASE_URL || runtimeOrigin;
const normalizedBaseUrl = rawBaseUrl.endsWith("/") ? rawBaseUrl.slice(0, -1) : rawBaseUrl;
const baseUrl = normalizedBaseUrl.endsWith("/api") ? normalizedBaseUrl : `${normalizedBaseUrl}/api`;
const TOKEN_STORAGE_KEY = "ocr-platform.tokens";

let tokens = loadStoredTokens();

function loadStoredTokens() {
  if (typeof window === "undefined") {
    return null;
  }
  const raw = window.localStorage.getItem(TOKEN_STORAGE_KEY);
  if (!raw) {
    return null;
  }
  try {
    const parsed = JSON.parse(raw);
    if (parsed && parsed.accessToken && parsed.refreshToken) {
      return parsed;
    }
  } catch (error) {
    console.warn("Failed to parse stored tokens", error);
  }
  return null;
}

function persistTokens(nextTokens) {
  tokens = nextTokens;
  if (typeof window === "undefined") {
    return;
  }
  if (nextTokens) {
    window.localStorage.setItem(TOKEN_STORAGE_KEY, JSON.stringify(nextTokens));
  } else {
    window.localStorage.removeItem(TOKEN_STORAGE_KEY);
  }
}

function normalizeTokenPair(pair) {
  if (!pair?.access_token || !pair?.refresh_token) {
    throw new Error("Invalid token payload received from server");
  }
  return {
    accessToken: pair.access_token,
    refreshToken: pair.refresh_token,
  };
}

async function refreshTokens() {
  if (!tokens?.refreshToken) {
    throw new Error("Refresh token unavailable");
  }

  const response = await fetch(`${baseUrl}/auth/refresh`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ refresh_token: tokens.refreshToken }),
  });

  if (!response.ok) {
    persistTokens(null);
    throw new Error("Session expired. Please login again.");
  }

  const data = await response.json();
  const normalized = normalizeTokenPair(data);
  persistTokens(normalized);
  return normalized;
}

async function request(path, options = {}) {
  const {
    method = "GET",
    json,
    formData,
    headers = {},
    auth = true,
    retry = true,
  } = options;

  const finalHeaders = { ...headers };
  let body = options.body ?? undefined;

  if (formData) {
    body = formData;
  } else if (json !== undefined) {
    finalHeaders["Content-Type"] = "application/json";
    body = JSON.stringify(json);
  } else if (
    body &&
    typeof body === "object" &&
    !(body instanceof FormData) &&
    !finalHeaders["Content-Type"]
  ) {
    finalHeaders["Content-Type"] = "application/json";
    body = JSON.stringify(body);
  }

  if (auth && tokens?.accessToken) {
    finalHeaders.Authorization = `Bearer ${tokens.accessToken}`;
  }

  let response;
  try {
    response = await fetch(`${baseUrl}${path}`, {
      method,
      headers: finalHeaders,
      body,
    });
  } catch (networkError) {
    const err = new Error("Network error. Please check your connection.");
    err.cause = networkError;
    throw err;
  }

  if (response.status === 401 && auth && retry && tokens?.refreshToken) {
    try {
      await refreshTokens();
      return request(path, { ...options, retry: false });
    } catch (refreshError) {
      persistTokens(null);
      const err = new Error(refreshError.message || "Authentication expired");
      err.status = 401;
      throw err;
    }
  }

  if (!response.ok) {
    const text = await response.text();
    const err = new Error(text || `Request failed with status ${response.status}`);
    err.status = response.status;
    throw err;
  }

  if (response.status === 204) {
    return null;
  }

  const contentType = response.headers.get("content-type");
  if (contentType && contentType.includes("application/json")) {
    return response.json();
  }

  const text = await response.text();
  return text;
}

async function login(credentials) {
  const data = await request("/auth/login", {
    method: "POST",
    json: credentials,
    auth: false,
  });
  const normalized = normalizeTokenPair(data);
  persistTokens(normalized);
  return normalized;
}

async function register(payload) {
  return request("/auth/register", {
    method: "POST",
    json: payload,
    auth: false,
  });
}

function logout() {
  persistTokens(null);
}

export const apiClient = {
  baseUrl,
  request,
  get(path, options = {}) {
    return request(path, { ...options, method: "GET" });
  },
  post(path, jsonBody, options = {}) {
    return request(path, { ...options, method: "POST", json: jsonBody });
  },
  postForm(path, formData, options = {}) {
    return request(path, { ...options, method: "POST", formData });
  },
  delete(path, options = {}) {
    return request(path, { ...options, method: "DELETE" });
  },
  login,
  register,
  logout,
  refreshAuth: refreshTokens,
  getTokens() {
    return tokens;
  },
  setTokens(pair) {
    persistTokens(pair);
  },
  clearTokens() {
    persistTokens(null);
  },
};

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\api\client.js ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\App.js ---
import { apiClient } from "../api/client";
import { createAuthForm, getStoredProfile } from "./AuthForm";
import { createUploadStatus } from "./UploadStatus";
import { createPreprocessView } from "./PreprocessView";
import { createOCRView } from "./OCRView";

const dashboardSections = [
  { id: "upload", label: "Upload", description: "Manage incoming documents" },
  { id: "preprocess", label: "Preprocess", description: "Review enhancement pipeline" },
  { id: "ocr", label: "OCR", description: "Inspect extracted content" },
];

function createSectionPlaceholder(title, lead, body) {
  const section = document.createElement("section");
  section.className = "placeholder-panel";

  const heading = document.createElement("h2");
  heading.textContent = title;

  const leadText = document.createElement("p");
  leadText.className = "placeholder-lead";
  leadText.textContent = lead;

  const bodyText = document.createElement("p");
  bodyText.textContent = body;

  section.append(heading, leadText, bodyText);
  return section;
}

export function createApp() {
  const container = document.createElement("div");
  container.className = "app-container";

  const header = document.createElement("header");
  header.className = "app-header";
  header.innerHTML = "<h1>OCR Platform</h1>";

  const main = document.createElement("main");
  main.className = "app-main";

  const uploadUi = createUploadStatus();
  const preprocessPanel = createPreprocessView();
  const ocrPanel = createOCRView();

  let currentProfile = getStoredProfile();
  let activeSection = "upload";

  const authForm = createAuthForm({
    onAuthChange: (tokens, profile) => {
      if (tokens) {
        currentProfile = profile ?? currentProfile ?? null;
        showDashboard(tokens, currentProfile);
      }
    },
  });

  const shell = document.createElement("div");
  shell.className = "app-shell";

  const sidebar = document.createElement("aside");
  sidebar.className = "app-sidebar";

  const brand = document.createElement("div");
  brand.className = "sidebar-brand";
  const brandBadge = document.createElement("div");
  brandBadge.className = "brand-badge";
  brandBadge.textContent = "OCR";
  const brandTitle = document.createElement("div");
  brandTitle.className = "brand-title";
  brandTitle.textContent = "Control Center";
  const brandSubtitle = document.createElement("p");
  brandSubtitle.className = "brand-subtitle";
  brandSubtitle.textContent = "Document intelligence workflows";
  brand.append(brandBadge, brandTitle, brandSubtitle);

  const nav = document.createElement("nav");
  nav.className = "sidebar-nav";
  const navButtons = new Map();

  function setActiveSection(sectionId) {
    activeSection = sectionId;
    navButtons.forEach((btn, id) => btn.classList.toggle("active", id === sectionId));
    renderSection(sectionId);
  }

  dashboardSections.forEach((section) => {
    const button = document.createElement("button");
    button.type = "button";
    button.className = "nav-item";
    button.textContent = section.label;
    button.title = section.description;
    button.addEventListener("click", () => {
      if (activeSection !== section.id) {
        setActiveSection(section.id);
      }
    });
    navButtons.set(section.id, button);
    nav.appendChild(button);
  });

  const sidebarFooter = document.createElement("div");
  sidebarFooter.className = "sidebar-footer";
  sidebarFooter.textContent = "Tip: Upload PDFs or high-resolution images for best OCR accuracy.";

  sidebar.append(brand, nav, sidebarFooter);

  const stage = document.createElement("div");
  stage.className = "app-stage";

  const topbar = document.createElement("div");
  topbar.className = "stage-topbar";

  const userBlock = document.createElement("div");
  userBlock.className = "stage-user";

  const userAvatar = document.createElement("div");
  userAvatar.className = "user-avatar";

  const userMeta = document.createElement("div");
  userMeta.className = "user-meta";

  const userName = document.createElement("span");
  userName.className = "user-name";

  const userEmail = document.createElement("span");
  userEmail.className = "user-email";

  userMeta.append(userName, userEmail);
  userBlock.append(userAvatar, userMeta);

  const logoutButton = document.createElement("button");
  logoutButton.type = "button";
  logoutButton.className = "danger";
  logoutButton.textContent = "Logout";
  logoutButton.addEventListener("click", () => {
    apiClient.logout();
    uploadUi.setTokens(null);
    showAuth();
  });

  topbar.append(userBlock, logoutButton);

  const content = document.createElement("div");
  content.className = "stage-content";

  stage.append(topbar, content);
  shell.append(sidebar, stage);

  function renderSection(sectionId) {
    content.innerHTML = "";
    switch (sectionId) {
      case "upload":
        content.append(uploadUi.element);
        break;
      case "preprocess":
        content.append(preprocessPanel.element);
        break;
      case "ocr":
        content.append(ocrPanel.element);
        break;
      default:
        content.append(uploadUi.element);
        break;
    }
  }

  function updateUser(profile) {
    const email = profile?.email?.trim() ?? "";
    const fullName = profile?.fullName?.trim() ?? "";
    const display = fullName || (email ? email.split("@")[0] : "Authenticated user");
    const avatarLetter = display.charAt(0).toUpperCase() || "U";

    userAvatar.textContent = avatarLetter;
    userName.textContent = display;
    userEmail.textContent = email ? `Logged in as ${email}` : "Session active";
  }

  function showAuth() {
    main.className = "app-main auth-mode";
    main.innerHTML = "";
    authForm.reset();
    uploadUi.setTokens(null);
    preprocessPanel.setTokens(null);
    ocrPanel.setTokens(null);
    main.append(authForm.element);
  }

  function showDashboard(tokens, profile) {
    main.className = "app-main dashboard-mode";
    main.innerHTML = "";
    updateUser(profile ?? currentProfile ?? {});
    uploadUi.setTokens(tokens);
    preprocessPanel.setTokens(tokens);
    ocrPanel.setTokens(tokens);
    activeSection = "";
    setActiveSection("upload");
    main.append(shell);
  }

  const initialTokens = apiClient.getTokens();

  if (initialTokens) {
    showDashboard(initialTokens, currentProfile);
  } else {
    showAuth();
  }

  container.append(header, main);

  return container;
}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\App.js ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\AuthForm.js ---
import { apiClient } from "../api/client";

const PROFILE_STORAGE_KEY = "ocr-platform.profile";

function loadProfile() {
  if (typeof window === "undefined") {
    return null;
  }
  const raw = window.localStorage.getItem(PROFILE_STORAGE_KEY);
  if (!raw) {
    return null;
  }
  try {
    const parsed = JSON.parse(raw);
    if (!parsed) {
      return null;
    }
    return {
      email: parsed.email ?? parsed.username ?? "",
      fullName: parsed.fullName ?? parsed.full_name ?? "",
    };
  } catch (error) {
    console.warn("Failed to parse stored profile", error);
    return null;
  }
}

function persistProfile(profile) {
  if (typeof window === "undefined") {
    return;
  }
  if (profile) {
    window.localStorage.setItem(PROFILE_STORAGE_KEY, JSON.stringify(profile));
  } else {
    window.localStorage.removeItem(PROFILE_STORAGE_KEY);
  }
}

function extractErrorMessage(error) {
  if (!error) {
    return "Unexpected error.";
  }
  if (error.message) {
    try {
      const parsed = JSON.parse(error.message);
      if (parsed?.detail) {
        return typeof parsed.detail === "string" ? parsed.detail : JSON.stringify(parsed.detail);
      }
    } catch (_) {
      // Ignore JSON parse failures, we'll fall back to the raw message.
    }
    return error.message;
  }
  return String(error);
}

export function getStoredProfile() {
  return loadProfile();
}

export function clearStoredProfile() {
  persistProfile(null);
}

export function createAuthForm({ onAuthChange } = {}) {
  const storedProfile = loadProfile();
  let currentProfile = storedProfile;
  let mode = "login";
  let isSubmitting = false;

  const container = document.createElement("div");
  container.className = "auth-page";

  const card = document.createElement("section");
  card.className = "auth-card";

  const title = document.createElement("h2");

  const status = document.createElement("p");
  status.className = "status-message";
  status.hidden = true;

  const form = document.createElement("form");
  form.className = "auth-form";

  const fullNameGroup = document.createElement("label");
  fullNameGroup.className = "input-group";
  const fullNameLabel = document.createElement("span");
  fullNameLabel.textContent = "Full name";
  const fullNameInput = document.createElement("input");
  fullNameInput.type = "text";
  fullNameInput.placeholder = "Ada Lovelace";
  fullNameInput.autocomplete = "name";
  if (storedProfile?.fullName) {
    fullNameInput.value = storedProfile.fullName;
  }
  fullNameGroup.append(fullNameLabel, fullNameInput);

  const emailGroup = document.createElement("label");
  emailGroup.className = "input-group";
  const emailLabel = document.createElement("span");
  emailLabel.textContent = "Email";
  const emailInput = document.createElement("input");
  emailInput.type = "email";
  emailInput.placeholder = "user@example.com";
  emailInput.autocomplete = "email";
  if (storedProfile?.email) {
    emailInput.value = storedProfile.email;
  }
  emailGroup.append(emailLabel, emailInput);

  const passwordGroup = document.createElement("label");
  passwordGroup.className = "input-group";
  const passwordLabel = document.createElement("span");
  passwordLabel.textContent = "Password";
  const passwordInput = document.createElement("input");
  passwordInput.type = "password";
  passwordInput.placeholder = "";
  passwordInput.autocomplete = "current-password";
  passwordGroup.append(passwordLabel, passwordInput);

  const submitButton = document.createElement("button");
  submitButton.type = "submit";

  form.append(fullNameGroup, emailGroup, passwordGroup, submitButton);

  const togglePrompt = document.createElement("p");
  togglePrompt.className = "auth-toggle";
  const toggleText = document.createElement("span");
  const toggleButton = document.createElement("button");
  toggleButton.type = "button";
  toggleButton.className = "link-button";
  togglePrompt.append(toggleText, toggleButton);

  card.append(title, status, form, togglePrompt);
  container.append(card);

  function setStatus(message, variant = "info") {
    if (!message) {
      status.textContent = "";
      status.hidden = true;
      status.className = "status-message";
      return;
    }
    status.hidden = false;
    status.textContent = message;
    status.className = `status-message status-${variant}`;
  }

  function notifyAuthChange(nextTokens) {
    if (typeof onAuthChange === "function") {
      onAuthChange(nextTokens, currentProfile);
    }
    container.dispatchEvent(
      new CustomEvent("authchange", {
        detail: {
          tokens: nextTokens,
          profile: currentProfile,
        },
      }),
    );
  }

  function updateMode(nextMode) {
    mode = nextMode;
    const isLogin = mode === "login";
    fullNameGroup.hidden = isLogin;
    passwordInput.autocomplete = isLogin ? "current-password" : "new-password";
    submitButton.textContent = isLogin ? "Login" : "Create account";
    title.textContent = isLogin ? "Welcome back" : "Create your account";
    toggleText.textContent = isLogin ? "Don't have an account? " : "Already registered? ";
    toggleButton.textContent = isLogin ? "Create one" : "Back to login";
  }

  function startSubmit() {
    isSubmitting = true;
    submitButton.disabled = true;
  }

  function endSubmit() {
    isSubmitting = false;
    submitButton.disabled = false;
  }

  async function handleSubmit(event) {
    event.preventDefault();
    if (isSubmitting) {
      return;
    }

    const email = emailInput.value.trim().toLowerCase();
    const password = passwordInput.value;
    const fullName = fullNameInput.value.trim();

    if (!email || !password) {
      setStatus("Email and password are required.", "error");
      return;
    }

    if (mode === "register" && !fullName) {
      setStatus("Please provide your full name to create an account.", "error");
      return;
    }

    startSubmit();

    try {
      if (mode === "login") {
        const tokenPair = await apiClient.login({ email, password });
        currentProfile = {
          email,
          fullName: currentProfile?.fullName ?? (fullName || ""),
        };
        persistProfile(currentProfile);
        passwordInput.value = "";
        setStatus(`Authenticated as ${email}.`, "success");
        notifyAuthChange(tokenPair);
      } else {
        const profile = await apiClient.register({
          email,
          password,
          full_name: fullName,
        });
        currentProfile = {
          email: profile.email ?? email,
          fullName: profile.full_name ?? profile.fullName ?? fullName,
        };
        persistProfile(currentProfile);
        setStatus("Account created. You can sign in now.", "success");
        updateMode("login");
        passwordInput.value = "";
        passwordInput.focus();
      }
    } catch (error) {
      const message = extractErrorMessage(error) || "Request failed.";
      setStatus(message, "error");
    } finally {
      endSubmit();
    }
  }

  toggleButton.addEventListener("click", () => {
    updateMode(mode === "login" ? "register" : "login");
    setStatus("", "info");
    passwordInput.value = "";
    if (mode === "register") {
      fullNameInput.focus();
    } else {
      passwordInput.focus();
    }
  });

  form.addEventListener("submit", handleSubmit);

  updateMode("login");
  setStatus("Sign in to manage your documents.", "info");

  return {
    element: container,
    reset() {
      updateMode("login");
      passwordInput.value = "";
      setStatus("Sign in to manage your documents.", "info");
      if (currentProfile?.email) {
        emailInput.value = currentProfile.email;
      }
      if (currentProfile?.fullName) {
        fullNameInput.value = currentProfile.fullName;
      }
    },
  };
}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\AuthForm.js ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\OCRView.js ---
import { apiClient } from "../api/client";

export function createOCRView() {
  const section = document.createElement("section");
  section.className = "ocr-section";

  const title = document.createElement("h2");
  title.textContent = "OCR Text Extraction";
  
  const status = document.createElement("p");
  status.className = "status-message";

  const controls = document.createElement("div");
  controls.className = "ocr-controls";
  
  const documentSelect = document.createElement("select");
  const extractButton = document.createElement("button");
  extractButton.textContent = "Extract Text";
  extractButton.disabled = true;

  controls.append(documentSelect, extractButton);

  const viewer = document.createElement("div");
  viewer.className = "ocr-viewer";
  
  const imagePanel = document.createElement("div");
  imagePanel.className = "ocr-image-panel";
  imagePanel.innerHTML = "<h3>Preprocessed Image</h3><div class='ocr-image-container'><p>Select a document</p></div>";
  
  const textPanel = document.createElement("div");
  textPanel.className = "ocr-text-panel";
  const textPanelTitle = document.createElement("h3");
  textPanelTitle.textContent = "Extracted Text";
  const textArea = document.createElement("textarea");
  textArea.className = "ocr-text-area";
  textArea.placeholder = 'Select a document and click "Extract Text" to start OCR extraction...';
  textArea.readOnly = false; // Editabil
  textPanel.append(textPanelTitle, textArea);
  
  viewer.append(imagePanel, textPanel);

  section.append(title, status, controls, viewer);

  let currentTokens = null;
  let documents = [];
  let selectedDocumentId = null;
  let pollingInterval = null;

  function setStatus(message, variant = "info") {
    status.textContent = message;
    status.className = `status-message status-${variant}`;
  }

  function stopPolling() {
    if (pollingInterval) {
      clearInterval(pollingInterval);
      pollingInterval = null;
    }
  }

  async function pollDocumentStatus(documentId) {
    stopPolling();
    
    pollingInterval = setInterval(async () => {
      try {
        const doc = await apiClient.get(`/documents/${documentId}`);
        
        // Update the document in our list
        const index = documents.findIndex(d => d.id === documentId);
        if (index >= 0) {
          documents[index] = doc;
        }
        
        // Update the select option text
        const option = Array.from(documentSelect.options).find(opt => opt.value === documentId);
        if (option) {
          option.textContent = `${doc.filename} (${doc.status})`;
        }
        
        // Check if OCR is done or failed
        const isCompleted = doc.status === "completed";
        const isFailed = doc.status === "failed";
        
        if (isCompleted) {
          stopPolling();
          setStatus("OCR extraction completed!", "success");
          textArea.value = doc.ocr_text || "[No text extracted]";
          extractButton.disabled = false;
        } else if (isFailed) {
          stopPolling();
          setStatus(`OCR extraction failed: ${doc.error_message || "Unknown error"}`, "error");
          extractButton.disabled = false;
        } else {
          // Still processing
          setStatus(`Processing OCR... (${doc.status})`, "info");
        }
      } catch (error) {
        console.error("Polling error:", error);
        stopPolling();
        setStatus("Failed to check OCR status.", "error");
        extractButton.disabled = false;
      }
    }, 2000); // Poll every 2 seconds
  }

  async function fetchImageBlob(documentId, variant) {
    try {
      const response = await fetch(`${apiClient.baseUrl}/documents/${documentId}/binary?variant=${variant}`, {
        headers: { 
          'Authorization': `Bearer ${currentTokens.accessToken}`,
          'Accept': 'image/*'
        }
      });
      
      if (!response.ok) {
        throw new Error(`Failed to fetch ${variant} image: ${response.statusText}`);
      }
      
      return await response.blob();
    } catch (error) {
      console.error(`Failed to fetch ${variant} image:`, error);
      return null;
    }
  }
  
  function renderImage(blob, defaultMessage) {
    const container = imagePanel.querySelector('.ocr-image-container');
    container.innerHTML = "";
    if (blob) {
      const img = document.createElement('img');
      img.src = URL.createObjectURL(blob);
      container.appendChild(img);
    } else {
      container.innerHTML = `<p>${defaultMessage}</p>`;
    }
  }

  async function updateView(doc) {
    if (!doc) {
      renderImage(null, "Select a document");
      textArea.value = "";
      textArea.placeholder = "Select a document to extract text...";
      return;
    }

    // Show preprocessed image (if available)
    const hasPreprocessed = ["queued_ocr", "ocr", "completed"].includes(doc.status);
    if (hasPreprocessed) {
      const processedBlob = await fetchImageBlob(doc.id, "preprocessed");
      renderImage(processedBlob, "Preprocessed image unavailable.");
    } else {
      // Fallback to original if not preprocessed yet
      const originalBlob = await fetchImageBlob(doc.id, "original");
      renderImage(originalBlob, "Image not preprocessed yet.");
    }

    // Only show OCR text if document status is 'completed'
    // This ensures text appears only after OCR extraction is done
    if (doc.status === "completed" && doc.ocr_text) {
      textArea.value = doc.ocr_text;
      textArea.placeholder = "Edit extracted text...";
    } else {
      textArea.value = "";
      textArea.placeholder = `Click "Extract Text" to start OCR extraction...`;
    }
  }

  async function onSelectChange() {
    stopPolling();
    selectedDocumentId = documentSelect.value;
    extractButton.disabled = !selectedDocumentId;
    const selectedDoc = documents.find(d => d.id === selectedDocumentId);
    await updateView(selectedDoc);
  }

  async function onExtractClick() {
    if (!selectedDocumentId) return;
    
    const selectedDoc = documents.find(d => d.id === selectedDocumentId);
    
    // Check if document needs to be processed first
    if (!["queued_ocr", "ocr", "completed"].includes(selectedDoc?.status)) {
      setStatus("Document must be preprocessed first. Go to Preprocess section.", "error");
      return;
    }

    // If already completed, just show the text
    if (selectedDoc?.status === "completed" && selectedDoc?.ocr_text) {
      textArea.value = selectedDoc.ocr_text;
      setStatus("OCR text already extracted.", "success");
      return;
    }

    // Start OCR extraction
    extractButton.disabled = true;
    setStatus("Starting OCR extraction...", "info");

    try {
      await apiClient.post(`/documents/${selectedDocumentId}/process`, {});
      setStatus("OCR extraction started. Checking status...", "info");
      await pollDocumentStatus(selectedDocumentId);
    } catch (error) {
      setStatus(error.message || "Failed to start OCR extraction.", "error");
      extractButton.disabled = false;
    }
  }

  async function fetchDocuments() {
    if (!currentTokens) return;
    try {
      const docs = await apiClient.get("/documents");
      // Only show images that have been preprocessed or completed
      documents = docs.filter(d => 
        d.content_type.startsWith('image/') && 
        ["queued_ocr", "ocr", "completed"].includes(d.status)
      );
      
      documentSelect.innerHTML = '<option value="">-- Select a document --</option>';
      documents.forEach(doc => {
        const option = document.createElement("option");
        option.value = doc.id;
        option.textContent = `${doc.filename} (${doc.status})`;
        documentSelect.appendChild(option);
      });
      
      if (documents.length === 0) {
        setStatus("No preprocessed documents available. Preprocess images first.", "info");
      } else {
        setStatus(`Loaded ${documents.length} preprocessed document(s).`, "success");
      }
    } catch (error) {
      setStatus("Failed to load documents.", "error");
    }
  }

  function setTokens(tokens) {
    currentTokens = tokens;
    if (tokens) {
      fetchDocuments();
    } else {
      stopPolling();
    }
  }
  
  // Listen for document upload events from other components
  const handleDocumentUploaded = () => {
    if (currentTokens) {
      fetchDocuments();
    }
  };
  
  // Listen for preprocessing completion events
  const handleDocumentPreprocessed = () => {
    if (currentTokens) {
      fetchDocuments();
    }
  };
  
  window.addEventListener('documentUploaded', handleDocumentUploaded);
  window.addEventListener('documentPreprocessed', handleDocumentPreprocessed);
  
  documentSelect.addEventListener("change", onSelectChange);
  extractButton.addEventListener("click", onExtractClick);
  
  setStatus("Select a preprocessed document to extract text.", "info");

  return { element: section, setTokens };
}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\OCRView.js ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\PreprocessView.js ---
import { apiClient } from "../api/client";

export function createPreprocessView() {
  const section = document.createElement("section");
  section.className = "preprocess-section";

  const title = document.createElement("h2");
  title.textContent = "Image Preprocessing";
  
  const status = document.createElement("p");
  status.className = "status-message";

  const controls = document.createElement("div");
  controls.className = "preprocess-controls";
  
  const documentSelect = document.createElement("select");
  const preprocessButton = document.createElement("button");
  preprocessButton.textContent = "Preprocess Image";
  preprocessButton.disabled = true;

  controls.append(documentSelect, preprocessButton);

  const viewer = document.createElement("div");
  viewer.className = "preprocess-viewer";
  
  const originalPanel = document.createElement("div");
  originalPanel.className = "image-panel";
  originalPanel.innerHTML = "<h3>Original</h3><div class='image-container'><p>Select a document</p></div>";
  
  const processedPanel = document.createElement("div");
  processedPanel.className = "image-panel";
  processedPanel.innerHTML = "<h3>Preprocessed</h3><div class='image-container'><p>Not processed yet</p></div>";
  
  viewer.append(originalPanel, processedPanel);

  section.append(title, status, controls, viewer);

  let currentTokens = null;
  let documents = [];
  let selectedDocumentId = null;
  let pollingInterval = null;

  function setStatus(message, variant = "info") {
    status.textContent = message;
    status.className = `status-message status-${variant}`;
  }

  function stopPolling() {
    if (pollingInterval) {
      clearInterval(pollingInterval);
      pollingInterval = null;
    }
  }

  async function pollDocumentStatus(documentId) {
    stopPolling(); // Clear any existing polling
    
    pollingInterval = setInterval(async () => {
      try {
        const doc = await apiClient.get(`/documents/${documentId}`);
        
        // Update the document in our list
        const index = documents.findIndex(d => d.id === documentId);
        if (index >= 0) {
          documents[index] = doc;
        }
        
        // Update the select option text
        const option = Array.from(documentSelect.options).find(opt => opt.value === documentId);
        if (option) {
          option.textContent = `${doc.filename} (${doc.status})`;
        }
        
        // Check if processing is done or failed
        const isProcessed = ["queued_ocr", "ocr", "completed"].includes(doc.status);
        const isFailed = doc.status === "failed";
        
        if (isProcessed) {
          stopPolling();
          setStatus("Preprocessing completed! Displaying result.", "success");
          await updateImageView(doc);
          preprocessButton.disabled = false;
          
          // Notify OCR component that preprocessing is complete
          window.dispatchEvent(new CustomEvent('documentPreprocessed', { detail: doc }));
        } else if (isFailed) {
          stopPolling();
          setStatus(`Preprocessing failed: ${doc.error_message || "Unknown error"}`, "error");
          preprocessButton.disabled = false;
        } else {
          // Still processing
          setStatus(`Processing... (${doc.status})`, "info");
        }
      } catch (error) {
        console.error("Polling error:", error);
        stopPolling();
        setStatus("Failed to check processing status.", "error");
        preprocessButton.disabled = false;
      }
    }, 2000); // Poll every 2 seconds
  }
  
  async function fetchImageBlob(documentId, variant) {
    try {
      const response = await fetch(`${apiClient.baseUrl}/documents/${documentId}/binary?variant=${variant}`, {
        headers: { 
          'Authorization': `Bearer ${currentTokens.accessToken}`,
          'Accept': 'image/*'
        }
      });
      
      if (!response.ok) {
        throw new Error(`Failed to fetch ${variant} image: ${response.statusText}`);
      }
      
      return await response.blob();
    } catch (error) {
      console.error(`Failed to fetch ${variant} image:`, error);
      return null;
    }
  }
  
  function renderImage(panel, blob, defaultMessage) {
    const container = panel.querySelector('.image-container');
    container.innerHTML = "";
    if (blob) {
      const img = document.createElement('img');
      img.src = URL.createObjectURL(blob);
      container.appendChild(img);
    } else {
      container.innerHTML = `<p>${defaultMessage}</p>`;
    }
  }

  async function updateImageView(doc) {
      if (!doc) {
        renderImage(originalPanel, null, "Select a document");
        renderImage(processedPanel, null, "Select a document");
        return;
      }

      const originalBlob = await fetchImageBlob(doc.id, "original");
      renderImage(originalPanel, originalBlob, "Original image unavailable.");

      const isProcessed = ["queued_ocr", "ocr", "completed"].includes(doc.status);
      if (isProcessed) {
        const processedBlob = await fetchImageBlob(doc.id, "preprocessed");
        renderImage(processedPanel, processedBlob, "Preprocessed image unavailable.");
      } else {
        renderImage(processedPanel, null, "Image has not been preprocessed yet.");
      }
  }

  async function onSelectChange() {
    stopPolling(); // Stop polling when changing selection
    selectedDocumentId = documentSelect.value;
    preprocessButton.disabled = !selectedDocumentId;
    const selectedDoc = documents.find(d => d.id === selectedDocumentId);
    updateImageView(selectedDoc);
  }

  async function onPreprocessClick() {
    if (!selectedDocumentId) return;
    
    preprocessButton.disabled = true;
    setStatus("Starting preprocessing...", "info");

    try {
      await apiClient.post(`/documents/${selectedDocumentId}/process`, {});
      setStatus("Preprocessing started. Checking status...", "info");
      // Start polling for status updates
      await pollDocumentStatus(selectedDocumentId);
    } catch (error) {
      setStatus(error.message || "Failed to start preprocessing.", "error");
      preprocessButton.disabled = false;
    }
  }

  async function fetchDocuments() {
    if (!currentTokens) return;
    try {
      const docs = await apiClient.get("/documents");
      documents = docs.filter(d => d.content_type.startsWith('image/')); // Only show images
      
      documentSelect.innerHTML = '<option value="">-- Select a document --</option>';
      documents.forEach(doc => {
        const option = document.createElement("option");
        option.value = doc.id;
        option.textContent = `${doc.filename} (${doc.status})`;
        documentSelect.appendChild(option);
      });
      setStatus(`Loaded ${documents.length} image documents.`, "success");
    } catch (error) {
      setStatus("Failed to load documents.", "error");
    }
  }

  function setTokens(tokens) {
    currentTokens = tokens;
    if (tokens) {
      fetchDocuments();
    } else {
      stopPolling(); // Stop polling when logging out
    }
  }
  
  // Listen for document upload events from other components
  const handleDocumentUploaded = () => {
    if (currentTokens) {
      fetchDocuments();
    }
  };
  
  window.addEventListener('documentUploaded', handleDocumentUploaded);
  
  documentSelect.addEventListener("change", onSelectChange);
  preprocessButton.addEventListener("click", onPreprocessClick);
  
  setStatus("Select a document to view and preprocess.", "info");

  return { element: section, setTokens };
}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\PreprocessView.js ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\UploadStatus.js ---
import { apiClient } from "../api/client";

export function createUploadStatus() {
  const section = document.createElement("section");
  section.className = "upload-section";

  const title = document.createElement("h2");
  title.textContent = "Documents";

  const status = document.createElement("p");
  status.className = "status-message";

  const controls = document.createElement("div");
  controls.className = "document-controls";

  const uploadForm = document.createElement("form");
  uploadForm.className = "upload-form";

  const fileInput = document.createElement("input");
  fileInput.type = "file";
  fileInput.accept = "image/*,application/pdf";

  const uploadButton = document.createElement("button");
  uploadButton.type = "submit";
  uploadButton.textContent = "Upload";

  uploadForm.append(fileInput, uploadButton);

  const refreshButton = document.createElement("button");
  refreshButton.type = "button";
  refreshButton.className = "secondary";
  refreshButton.textContent = "Refresh";

  controls.append(uploadForm, refreshButton);

  const table = document.createElement("table");
  table.className = "document-table";
  const thead = document.createElement("thead");
  thead.innerHTML = "<tr><th>Filename</th><th>Actions</th></tr>";
  const tbody = document.createElement("tbody");
  table.append(thead, tbody);

  section.append(title, status, controls, table);

  let currentTokens = null;
  let documents = [];
  let isLoading = false;

  function setStatus(message, variant = "info") {
    status.textContent = message;
    status.className = `status-message status-${variant}`;
  }

  function createActionButton(label, handler, variant) {
    const button = document.createElement("button");
    button.type = "button";
    button.textContent = label;
    button.className = `table-action${variant ? ` ${variant}` : ""}`;
    button.addEventListener("click", (event) => {
      event.preventDefault();
      event.stopPropagation();
      handler();
    });
    return button;
  }

  function renderDocuments() {
    tbody.innerHTML = "";

    if (!documents.length) {
      const emptyRow = document.createElement("tr");
      const cell = document.createElement("td");
      cell.colSpan = 2;
      cell.textContent = currentTokens
        ? "No documents uploaded yet."
        : "Authenticate to view documents.";
      emptyRow.appendChild(cell);
      tbody.appendChild(emptyRow);
      return;
    }

    documents.forEach((doc) => {
      const row = document.createElement("tr");

      const filenameCell = document.createElement("td");
      filenameCell.textContent = doc.filename;

      const actionsCell = document.createElement("td");
      actionsCell.append(
        createActionButton("Delete", () => deleteDocument(doc.id), "danger"),
      );

      row.append(filenameCell, actionsCell);
      tbody.appendChild(row);
    });
  }

  async function fetchDocuments() {
    if (!currentTokens) {
      documents = [];
      renderDocuments();
      setStatus("Authenticate to manage documents.", "info");
      return;
    }

    if (isLoading) {
      return;
    }

    isLoading = true;
    refreshButton.disabled = true;
    setStatus("Loading documents...", "info");
    try {
      const response = await apiClient.get("/documents");
      documents = Array.isArray(response) ? response : [];
      renderDocuments();
      if (documents.length) {
        setStatus(`Loaded ${documents.length} document${documents.length === 1 ? "" : "s"}.`, "success");
      } else {
        setStatus("No documents uploaded yet.", "info");
      }
    } catch (error) {
      setStatus(error.message || "Failed to load documents.", "error");
    } finally {
      isLoading = false;
      refreshButton.disabled = !currentTokens;
    }
  }

  async function deleteDocument(documentId) {
    if (!window.confirm("Delete this document permanently?")) {
      return;
    }
    try {
      await apiClient.delete(`/documents/${documentId}`);
      setStatus("Document deleted.", "success");
      await fetchDocuments();
    } catch (error) {
      setStatus(error.message || "Failed to delete document.", "error");
    }
  }

  uploadForm.addEventListener("submit", async (event) => {
    event.preventDefault();
    if (!currentTokens) {
      setStatus("Login to upload documents.", "error");
      return;
    }

    const file = fileInput.files?.[0];
    if (!file) {
      setStatus("Select a file before uploading.", "error");
      return;
    }

    uploadButton.disabled = true;
    try {
      const formData = new FormData();
      formData.append("file", file);
      const result = await apiClient.postForm("/documents", formData);
      const document = result?.document || result;
      setStatus(`Uploaded ${document.filename}.`, "success");
      fileInput.value = "";
      await fetchDocuments();
      
      // Notify other components that a new document was uploaded
      window.dispatchEvent(new CustomEvent('documentUploaded', { detail: document }));
    } catch (error) {
      setStatus(error.message || "Upload failed.", "error");
    } finally {
      uploadButton.disabled = false;
    }
  });

  refreshButton.addEventListener("click", () => {
    if (!isLoading) {
      fetchDocuments();
    }
  });

  function setTokens(tokens) {
    currentTokens = tokens;
    const hasAuth = Boolean(tokens?.accessToken);
    fileInput.disabled = !hasAuth;
    uploadButton.disabled = !hasAuth;
    refreshButton.disabled = !hasAuth;
    section.classList.toggle("requires-auth", !hasAuth);
    if (hasAuth) {
      fetchDocuments();
    } else {
      documents = [];
      renderDocuments();
      setStatus("Authenticate to manage documents.", "info");
    }
  }

  setStatus("Authenticate to manage documents.", "info");

  return { element: section, setTokens };
}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\components\UploadStatus.js ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\styles\main.css ---
body {
  margin: 0;
  font-family: Arial, sans-serif;
  background-color: #f5f7fb;
  color: #1f2933;
}

.app-container {
  display: flex;
  flex-direction: column;
  min-height: 100vh;
}

.app-header {
  background: linear-gradient(90deg, #1d4ed8 0%, #4338ca 100%);
  color: white;
  padding: 1.75rem 2rem;
  font-size: 1.5rem;
  font-weight: 700;
  letter-spacing: 0.05em;
}

.app-main {
  flex: 1;
  padding: 2rem;
}

.app-main.auth-mode {
  display: flex;
  align-items: center;
  justify-content: center;
}

.app-main.dashboard-mode {
  display: flex;
  padding: 1.5rem 2rem;
  background: linear-gradient(180deg, #eef2ff 0%, #f8fbff 100%);
}

.auth-page {
  width: 100%;
  display: flex;
  justify-content: center;
}

.auth-card {
  width: min(100%, 420px);
  display: flex;
  flex-direction: column;
  gap: 1.25rem;
}

.auth-card h2 {
  margin: 0;
}

section {
  background: white;
  border-radius: 8px;
  padding: 1.5rem;
  box-shadow: 0 10px 15px -3px rgb(15 23 42 / 0.1), 0 4px 6px -4px rgb(15 23 42 / 0.1);
}

button {
  background: #1d4ed8;
  border: none;
  border-radius: 6px;
  color: white;
  cursor: pointer;
  padding: 0.6rem 1.2rem;
  transition: background 0.2s ease;
}

button:hover {
  background: #2563eb;
}

button:disabled {
  opacity: 0.6;
  cursor: not-allowed;
}

button.secondary {
  background: #374151;
}

button.secondary:hover {
  background: #4b5563;
}

button.danger {
  background: #b91c1c;
}

button.danger:hover {
  background: #dc2626;
}

.link-button {
  background: transparent;
  color: #1d4ed8;
  padding: 0;
  border: none;
  font-size: 1rem;
  cursor: pointer;
  text-decoration: underline;
}

.link-button:hover {
  background: transparent;
  color: #2563eb;
}

.button-row {
  display: flex;
  flex-wrap: wrap;
  gap: 0.5rem;
  margin-top: 1rem;
}

.input-group {
  display: flex;
  flex-direction: column;
  gap: 0.4rem;
  margin-bottom: 0.8rem;
  font-weight: 600;
}

.input-group input {
  border: 1px solid #cbd5f5;
  border-radius: 6px;
  padding: 0.5rem 0.75rem;
  font-size: 1rem;
}

.status-message {
  margin: 0 0 1rem;
  padding: 0.75rem 1rem;
  border-radius: 6px;
  background: #eff6ff;
  color: #1d4ed8;
  font-weight: 500;
}

.auth-form {
  display: flex;
  flex-direction: column;
  gap: 0.8rem;
}

.auth-toggle {
  margin: 0;
  font-size: 0.95rem;
}

.auth-toggle span {
  margin-right: 0.35rem;
}

.status-message.status-success {
  background: #ecfdf5;
  color: #047857;
}

.status-message.status-error {
  background: #fef2f2;
  color: #b91c1c;
}

.status-message.status-info {
  background: #eff6ff;
  color: #1d4ed8;
}

.upload-section.requires-auth {
  opacity: 0.7;
}

.app-shell {
  flex: 1;
  display: flex;
  background: white;
  border-radius: 22px;
  overflow: hidden;
  box-shadow: 0 25px 45px -20px rgb(15 23 42 / 0.35);
  min-height: 0;
}

.app-sidebar {
  width: 260px;
  background: linear-gradient(180deg, #1d4ed8 0%, #312e81 100%);
  color: #e0e7ff;
  display: flex;
  flex-direction: column;
  gap: 2rem;
  padding: 2.5rem 2rem;
}

.sidebar-brand {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.brand-badge {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  width: 56px;
  height: 56px;
  border-radius: 18px;
  background: rgba(255, 255, 255, 0.14);
  font-weight: 700;
  letter-spacing: 0.12em;
}

.brand-title {
  font-size: 1.35rem;
  font-weight: 700;
}

.brand-subtitle {
  margin: 0;
  font-size: 0.95rem;
  color: rgba(224, 231, 255, 0.75);
  line-height: 1.4;
}

.sidebar-nav {
  display: flex;
  flex-direction: column;
  gap: 0.6rem;
}

.sidebar-nav .nav-item {
  width: 100%;
  background: transparent;
  border: none;
  color: inherit;
  padding: 0.85rem 1rem;
  border-radius: 14px;
  font-size: 1rem;
  font-weight: 600;
  text-align: left;
  transition: transform 0.2s ease, background 0.2s ease, color 0.2s ease;
}

.sidebar-nav .nav-item:hover {
  background: rgba(255, 255, 255, 0.16);
  transform: translateX(6px);
}

.sidebar-nav .nav-item.active {
  background: rgba(255, 255, 255, 0.22);
  color: #ffffff;
  box-shadow: inset 0 0 0 1px rgba(255, 255, 255, 0.15);
}

.sidebar-footer {
  margin-top: auto;
  font-size: 0.85rem;
  line-height: 1.4;
  color: rgba(224, 231, 255, 0.7);
}

.app-stage {
  flex: 1;
  min-width: 0;
  display: flex;
  flex-direction: column;
  background: linear-gradient(180deg, #f8fbff 0%, #eef2ff 100%);
}

.stage-topbar {
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 1.75rem 2.5rem;
  background: rgba(255, 255, 255, 0.9);
  border-bottom: 1px solid rgba(148, 163, 184, 0.2);
  backdrop-filter: blur(4px);
}

.stage-user {
  display: flex;
  align-items: center;
  gap: 1rem;
}

.user-avatar {
  width: 48px;
  height: 48px;
  border-radius: 16px;
  background: linear-gradient(135deg, #2563eb 0%, #7c3aed 100%);
  color: white;
  display: flex;
  align-items: center;
  justify-content: center;
  font-weight: 700;
  font-size: 1.2rem;
}

.user-meta {
  display: flex;
  flex-direction: column;
  gap: 0.25rem;
}

.user-name {
  font-size: 1.1rem;
  font-weight: 600;
  color: #1f2937;
}

.user-email {
  font-size: 0.9rem;
  color: #64748b;
}

.stage-content {
  flex: 1;
  padding: 2.5rem 2.75rem;
  overflow-y: auto;
  display: grid;
  gap: 1.5rem;
  align-content: flex-start;
}

.stage-content > section {
  width: 100%;
}

.placeholder-panel {
  display: flex;
  flex-direction: column;
  gap: 1rem;
}

.placeholder-panel .placeholder-lead {
  font-size: 1.05rem;
  font-weight: 600;
  color: #475569;
}

.placeholder-panel p {
  margin: 0;
  color: #64748b;
  line-height: 1.6;
}

.upload-section {
  width: 100%;
  max-width: 960px;
}

.document-controls {
  display: flex;
  gap: 1rem;
  align-items: center;
  flex-wrap: wrap;
  margin-bottom: 1rem;
}

.upload-form {
  display: flex;
  gap: 0.6rem;
  align-items: center;
}

.document-table {
  width: 100%;
  border-collapse: collapse;
  margin-bottom: 1rem;
}

.document-table th,
.document-table td {
  padding: 0.6rem;
  border-bottom: 1px solid #e5e7eb;
  text-align: left;
}

.document-table tr:hover {
  background: #f9fafb;
}

.document-table tr.selected {
  background: #e0e7ff;
}

.table-action {
  margin-right: 0.4rem;
  padding: 0.4rem 0.8rem;
  font-size: 0.85rem;
}

.document-detail {
  border-top: 1px solid #e5e7eb;
  padding-top: 1rem;
}

.document-meta {
  margin-bottom: 0.8rem;
  font-size: 0.9rem;
}

.document-meta p {
  margin: 0.2rem 0;
}

.document-meta .error {
  color: #b91c1c;
  font-weight: 600;
}

.document-output {
  background: #f9fafb;
  padding: 1rem;
  border-radius: 6px;
  max-height: 240px;
  overflow: auto;
  white-space: pre-wrap;
}

.status-label {
  display: inline-flex;
  align-items: center;
  padding: 0.2rem 0.6rem;
  border-radius: 9999px;
  font-size: 0.85rem;
  text-transform: capitalize;
  background: #e0f2fe;
  color: #0369a1;
}

.status-label.status-queued-preprocessing,
.status-label.status-processing,
.status-label.status-preprocessing,
.status-label.status-queued-ocr,
.status-label.status-ocr {
  background: #fef3c7;
  color: #b45309;
}

.status-label.status-completed {
  background: #ecfdf5;
  color: #047857;
}

.status-label.status-failed {
  background: #fee2e2;
  color: #b91c1c;
}

@media (max-width: 960px) {
  .app-main.dashboard-mode {
    padding: 1rem;
  }

  .app-shell {
    flex-direction: column;
    border-radius: 18px;
  }

  .app-sidebar {
    width: 100%;
    flex-direction: row;
    align-items: center;
    gap: 1.5rem;
  }

  .sidebar-brand {
    flex-direction: row;
    align-items: center;
  }

  .brand-title {
    font-size: 1.1rem;
  }

  .sidebar-brand p {
    display: none;
  }

  .sidebar-nav {
    flex-direction: row;
    width: 100%;
  }

  .sidebar-nav .nav-item {
    flex: 1;
    text-align: center;
    padding: 0.75rem;
  }

  .sidebar-footer {
    display: none;
  }

  .stage-topbar {
    padding: 1.25rem 1.5rem;
  }

  .stage-content {
    padding: 1.75rem 1.25rem;
  }

  .upload-section {
    max-width: 100%;
  }
}

/* Preprocess View Styles */
.preprocess-controls {
  display: flex;
  gap: 1rem;
  margin-bottom: 1.5rem;
  align-items: center;
}

.preprocess-controls select {
  padding: 0.5rem;
  border-radius: 6px;
  border: 1px solid #cbd5f5;
  min-width: 250px;
}

.preprocess-viewer {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 2rem;
  margin-top: 1rem;
}

.image-panel h3 {
  margin-top: 0;
  color: #374151;
  border-bottom: 1px solid #e5e7eb;
  padding-bottom: 0.5rem;
}

.image-panel .image-container {
  width: 100%;
  min-height: 200px;
  background-color: #f8fafc;
  border: 1px dashed #cbd5f5;
  border-radius: 8px;
  display: flex;
  align-items: center;
  justify-content: center;
  padding: 1rem;
}

.image-panel .image-container img {
  max-width: 100%;
  max-height: 400px;
  object-fit: contain;
  border-radius: 4px;
}

.image-panel .image-container p {
  color: #64748b;
}

/* OCR View Styles */
.ocr-controls {
  display: flex;
  gap: 1rem;
  margin-bottom: 1.5rem;
  align-items: center;
}

.ocr-controls select {
  padding: 0.5rem;
  border-radius: 6px;
  border: 1px solid #cbd5f5;
  min-width: 250px;
}

.ocr-viewer {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 2rem;
  margin-top: 1rem;
}

.ocr-image-panel h3,
.ocr-text-panel h3 {
  margin-top: 0;
  color: #374151;
  border-bottom: 1px solid #e5e7eb;
  padding-bottom: 0.5rem;
}

.ocr-image-container {
  width: 100%;
  min-height: 200px;
  background-color: #f8fafc;
  border: 1px dashed #cbd5f5;
  border-radius: 8px;
  display: flex;
  align-items: center;
  justify-content: center;
  padding: 1rem;
}

.ocr-image-container img {
  max-width: 100%;
  max-height: 400px;
  object-fit: contain;
  border-radius: 4px;
}

.ocr-image-container p {
  color: #64748b;
}

.ocr-text-area {
  width: 100%;
  min-height: 400px;
  padding: 1rem;
  border: 1px solid #cbd5f5;
  border-radius: 8px;
  font-family: 'Courier New', monospace;
  font-size: 0.95rem;
  line-height: 1.6;
  resize: vertical;
  background-color: #ffffff;
}

.ocr-text-area:focus {
  outline: none;
  border-color: #1d4ed8;
  box-shadow: 0 0 0 3px rgba(29, 78, 216, 0.1);
}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\frontend\src\styles\main.css ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\Dockerfile ---
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app:/app/shared

COPY gateway/requirements.txt ./requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

COPY gateway/src ./src
COPY shared/python ./shared

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\Dockerfile ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\requirements.txt ---
fastapi==0.111.0
uvicorn[standard]==0.30.1
httpx==0.27.0
pydantic[email]==2.9.1
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
orjson==3.10.7
asyncpg==0.29.0

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\requirements.txt ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\config.py ---
import os
from dataclasses import dataclass
from typing import Literal


@dataclass(frozen=True)
class Settings:
    service_name: str = os.getenv("SERVICE_NAME", "gateway")
    jwt_secret_key: str = os.getenv("JWT_SECRET_KEY", "change-me")
    jwt_algorithm: str = "HS256"
    jwt_access_ttl_seconds: int = int(os.getenv("JWT_ACCESS_TTL_SECONDS", "900"))
    jwt_refresh_ttl_seconds: int = int(os.getenv("JWT_REFRESH_TTL_SECONDS", "604800"))
    postgres_dsn: str = os.getenv("POSTGRES_DSN", "postgresql+asyncpg://ocr_admin:ocr_admin@postgres:5432/ocr_platform")
    user_service_url: str = os.getenv("USER_SERVICE_URL", "http://user-service:8001")
    document_service_url: str = os.getenv("DOCUMENT_SERVICE_URL", "http://document-service:8002")
    broker_service_url: str = os.getenv("BROKER_SERVICE_URL", "http://broker-service:8003")
    environment: Literal["dev", "prod", "test"] = os.getenv("ENVIRONMENT", "dev")


def get_settings() -> Settings:
    return Settings()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\config.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\main.py ---
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from .api.routes import router as api_router
from .config import get_settings

settings = get_settings()
app = FastAPI(title="OCR Gateway", version="0.1.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.include_router(api_router, prefix="/api")


@app.get("/health", tags=["system"])
async def health() -> dict[str, str]:
    return {"status": "ok", "service": settings.service_name}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\main.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\api\routes.py ---
from __future__ import annotations

from collections.abc import AsyncGenerator

import httpx
from fastapi import APIRouter, Depends, File, HTTPException, Response, UploadFile, status

from ..clients.document_client import DocumentServiceClient
from ..clients.user_client import UserServiceClient
from ..config import get_settings
from ..core.auth import get_current_user_id
from ..schemas.auth import LoginRequest, RefreshRequest, RegisterRequest, TokenPair
from ..schemas.document import DocumentMetadata, DocumentUploadResponse
from ..schemas.user import UserProfile

settings = get_settings()
router = APIRouter()


async def get_user_client() -> AsyncGenerator[UserServiceClient, None]:
    client = UserServiceClient(settings.user_service_url)
    try:
        yield client
    finally:
        await client.close()


async def get_document_client() -> AsyncGenerator[DocumentServiceClient, None]:
    client = DocumentServiceClient(settings.document_service_url)
    try:
        yield client
    finally:
        await client.close()


@router.get("/health", tags=["system"])
async def healthcheck() -> dict[str, str]:
    """Return service health status."""
    return {"status": "ok"}


@router.post("/auth/register", response_model=UserProfile, status_code=status.HTTP_201_CREATED, tags=["auth"])
async def register_user(
    payload: RegisterRequest,
    client: UserServiceClient = Depends(get_user_client),
) -> UserProfile:
    try:
        data = await client.register(payload.model_dump())
        return UserProfile.model_validate(data)
    except httpx.HTTPStatusError as exc:
        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text) from exc


@router.post("/auth/login", response_model=TokenPair, tags=["auth"])
async def login_user(
    payload: LoginRequest,
    client: UserServiceClient = Depends(get_user_client),
) -> TokenPair:
    try:
        data = await client.login(payload.model_dump())
        return TokenPair.model_validate(data)
    except httpx.HTTPStatusError as exc:
        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text) from exc


@router.post("/auth/refresh", response_model=TokenPair, tags=["auth"])
async def refresh_token(
    payload: RefreshRequest,
    client: UserServiceClient = Depends(get_user_client),
) -> TokenPair:
    try:
        data = await client.refresh(payload.model_dump())
        return TokenPair.model_validate(data)
    except httpx.HTTPStatusError as exc:
        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text) from exc


@router.get("/documents", response_model=list[DocumentMetadata], tags=["documents"])
async def list_documents(
    user_id: str = Depends(get_current_user_id),
    client: DocumentServiceClient = Depends(get_document_client),
) -> list[DocumentMetadata]:
    try:
        data = await client.list_documents(user_id)
        return [DocumentMetadata.model_validate(item) for item in data]
    except httpx.HTTPStatusError as exc:
        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text) from exc


@router.post("/documents", response_model=DocumentUploadResponse, status_code=status.HTTP_201_CREATED, tags=["documents"])
async def upload_document(
    file: UploadFile = File(...),
    user_id: str = Depends(get_current_user_id),
    client: DocumentServiceClient = Depends(get_document_client),
) -> DocumentUploadResponse:
    content = await file.read()
    if not content:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="empty file")
    try:
        data = await client.upload_document(
            user_id,
            filename=file.filename or "upload",
            content_type=file.content_type or "application/octet-stream",
            content=content,
        )
        return DocumentUploadResponse(document=DocumentMetadata.model_validate(data))
    except httpx.HTTPStatusError as exc:
        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text) from exc


@router.get("/documents/{document_id}", response_model=DocumentMetadata, tags=["documents"])
async def get_document(
    document_id: str,
    user_id: str = Depends(get_current_user_id),
    client: DocumentServiceClient = Depends(get_document_client),
) -> DocumentMetadata:
    try:
        data = await client.get_document(user_id, document_id)
        return DocumentMetadata.model_validate(data)
    except httpx.HTTPStatusError as exc:
        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text) from exc


@router.delete(
    "/documents/{document_id}",
    status_code=status.HTTP_204_NO_CONTENT,
    tags=["documents"],
    response_class=Response,
)
async def delete_document(
    document_id: str,
    user_id: str = Depends(get_current_user_id),
    client: DocumentServiceClient = Depends(get_document_client),
) -> Response:
    try:
        await client.delete_document(user_id, document_id)
    except httpx.HTTPStatusError as exc:
        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text) from exc
    return Response(status_code=status.HTTP_204_NO_CONTENT)


@router.post("/documents/{document_id}/process", response_model=DocumentMetadata, tags=["documents"])
async def requeue_document(
    document_id: str,
    user_id: str = Depends(get_current_user_id),
    client: DocumentServiceClient = Depends(get_document_client),
) -> DocumentMetadata:
    try:
        data = await client.requeue_document(user_id, document_id)
        return DocumentMetadata.model_validate(data)
    except httpx.HTTPStatusError as exc:
        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text) from exc


@router.get("/documents/{document_id}/binary", response_class=Response, tags=["documents"])
async def get_document_binary(
    document_id: str,
    variant: str = "original",
    user_id: str = Depends(get_current_user_id),
    client: DocumentServiceClient = Depends(get_document_client),
) -> Response:
    try:
        content = await client.get_document_binary(document_id, variant)
        media_type = "image/png" if variant == "preprocessed" else "application/octet-stream"
        return Response(content=content, media_type=media_type)
    except httpx.HTTPStatusError as exc:
        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text) from exc

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\api\routes.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\api\__init__.py ---

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\api\__init__.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\clients\document_client.py ---
from __future__ import annotations

from typing import Any

import httpx


class DocumentServiceClient:
    def __init__(self, base_url: str, *, timeout: float = 10.0) -> None:
        self._client = httpx.AsyncClient(base_url=base_url, timeout=timeout)

    async def close(self) -> None:
        await self._client.aclose()

    async def health(self) -> dict[str, Any]:
        response = await self._client.get("/health")
        response.raise_for_status()
        return response.json()

    async def list_documents(self, user_id: str) -> list[dict[str, Any]]:
        response = await self._client.get("/documents", headers={"X-User-Id": user_id})
        response.raise_for_status()
        return response.json()

    async def get_document(self, user_id: str, document_id: str) -> dict[str, Any]:
        response = await self._client.get(f"/documents/{document_id}", headers={"X-User-Id": user_id})
        response.raise_for_status()
        return response.json()

    async def upload_document(
        self,
        user_id: str,
        *,
        filename: str,
        content_type: str,
        content: bytes,
    ) -> dict[str, Any]:
        files = {"file": (filename, content, content_type)}
        response = await self._client.post("/documents", headers={"X-User-Id": user_id}, files=files)
        response.raise_for_status()
        return response.json()

    async def delete_document(self, user_id: str, document_id: str) -> None:
        response = await self._client.delete(f"/documents/{document_id}", headers={"X-User-Id": user_id})
        response.raise_for_status()

    async def requeue_document(self, user_id: str, document_id: str) -> dict[str, Any]:
        response = await self._client.post(
            f"/documents/{document_id}/process",
            headers={"X-User-Id": user_id},
        )
        response.raise_for_status()
        return response.json()

    async def get_document_binary(self, document_id: str, variant: str = "original") -> bytes:
        response = await self._client.get(
            f"/internal/documents/{document_id}/binary",
            params={"variant": variant},
        )
        response.raise_for_status()
        return response.content

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\clients\document_client.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\clients\user_client.py ---
from __future__ import annotations

from typing import Any

import httpx


class UserServiceClient:
    def __init__(self, base_url: str, *, timeout: float = 10.0) -> None:
        self._client = httpx.AsyncClient(base_url=base_url, timeout=timeout)

    async def close(self) -> None:
        await self._client.aclose()

    async def health(self) -> dict[str, Any]:
        response = await self._client.get("/health")
        response.raise_for_status()
        return response.json()

    async def register(self, payload: dict[str, Any]) -> dict[str, Any]:
        response = await self._client.post("/auth/register", json=payload)
        response.raise_for_status()
        return response.json()

    async def login(self, payload: dict[str, Any]) -> dict[str, Any]:
        response = await self._client.post("/auth/login", json=payload)
        response.raise_for_status()
        return response.json()

    async def refresh(self, payload: dict[str, Any]) -> dict[str, Any]:
        response = await self._client.post("/auth/refresh", json=payload)
        response.raise_for_status()
        return response.json()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\clients\user_client.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\core\auth.py ---
from __future__ import annotations

from fastapi import Depends, HTTPException, Header, status

from shared.utils.jwt import decode_token

from ..config import get_settings

settings = get_settings()


def extract_token(authorization: str | None) -> str:
    if not authorization:
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="missing authorization header")
    try:
        scheme, token = authorization.split(" ", 1)
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="invalid authorization header") from exc
    if scheme.lower() != "bearer":
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="invalid authentication scheme")
    return token


def get_current_user_id(authorization: str | None = Header(default=None, alias="Authorization")) -> str:
    token = extract_token(authorization)
    try:
        payload = decode_token(token=token, secret_key=settings.jwt_secret_key, algorithm="HS256")
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="invalid token") from exc
    if payload.get("scope") != "access":
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="invalid token scope")
    return str(payload.get("sub"))

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\core\auth.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\schemas\auth.py ---
from pydantic import BaseModel, EmailStr


class RegisterRequest(BaseModel):
    email: EmailStr
    password: str
    full_name: str


class LoginRequest(BaseModel):
    email: EmailStr
    password: str


class RefreshRequest(BaseModel):
    refresh_token: str


class TokenPair(BaseModel):
    access_token: str
    refresh_token: str
    token_type: str = "bearer"

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\schemas\auth.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\schemas\document.py ---
from datetime import datetime
from typing import Literal, Optional

from pydantic import BaseModel

DocumentStatus = Literal[
    "uploaded",
    "queued_preprocessing",
    "preprocessing",
    "queued_ocr",
    "ocr",
    "completed",
    "failed",
]


class DocumentMetadata(BaseModel):
    id: str
    owner_id: str
    filename: str
    content_type: str
    size_bytes: int
    status: DocumentStatus
    created_at: datetime
    updated_at: datetime
    error_message: Optional[str] = None
    ocr_text: Optional[str] = None


class DocumentUploadResponse(BaseModel):
    document: DocumentMetadata

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\schemas\document.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\schemas\user.py ---
from datetime import datetime

from pydantic import BaseModel, EmailStr


class UserProfile(BaseModel):
    id: int
    email: EmailStr
    full_name: str
    created_at: datetime
    updated_at: datetime

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\gateway\src\schemas\user.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\infrastructure\broker\definitions.json ---
{
  "topics": [
    {
      "name": "image_preprocess",
      "max_retries": 5,
      "retry_delay_seconds": 30
    },
    {
      "name": "ocr_extract",
      "max_retries": 5,
      "retry_delay_seconds": 30
    },
    {
      "name": "document_events",
      "max_retries": 5,
      "retry_delay_seconds": 15
    }
  ]
}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\infrastructure\broker\definitions.json ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\Dockerfile ---
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app:/app/shared

COPY processing-services/image-preprocessing-service/requirements.txt ./requirements.txt
RUN apt-get update && apt-get install -y --no-install-recommends \
    libgl1 \
    && rm -rf /var/lib/apt/lists/*
RUN pip install --no-cache-dir -r requirements.txt

COPY processing-services/image-preprocessing-service/src ./src
COPY shared/python ./shared

CMD ["python", "-m", "src.main"]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\Dockerfile ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\requirements.txt ---
opencv-python-headless==4.10.0.84
pillow==10.3.0
httpx==0.27.0
orjson==3.10.7

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\requirements.txt ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\src\main.py ---
from __future__ import annotations

import asyncio
import base64
import logging
from typing import Any

import httpx

from shared.utils.broker import AsyncBrokerClient

from .core.config import get_settings
from .pipelines.preprocess import preprocess_image

logger = logging.getLogger("image-preprocessing-service")
logging.basicConfig(level=logging.INFO)

settings = get_settings()


async def fetch_original(client: httpx.AsyncClient, document_id: str) -> bytes:
    response = await client.get(
        f"/api/internal/documents/{document_id}/binary",
        params={"variant": "original"},
    )
    response.raise_for_status()
    return response.content


async def upload_preprocessed(client: httpx.AsyncClient, document_id: str, data: bytes) -> None:
    payload = {
        "variant": "preprocessed",
        "data_base64": base64.b64encode(data).decode("ascii"),
    }
    response = await client.post(f"/api/internal/documents/{document_id}/binary", json=payload)
    response.raise_for_status()


async def update_status(client: httpx.AsyncClient, document_id: str, status_value: str) -> None:
    response = await client.post(
        f"/api/internal/documents/{document_id}/status",
        json={"status": status_value},
    )
    response.raise_for_status()


async def mark_failed(client: httpx.AsyncClient, document_id: str, message: str) -> None:
    response = await client.post(
        f"/api/internal/documents/{document_id}/fail",
        json={"error_message": message},
    )
    response.raise_for_status()


async def process_job(
    broker: AsyncBrokerClient,
    doc_client: httpx.AsyncClient,
    job: dict[str, Any],
) -> None:
    item_id = job["id"]
    payload = job.get("payload", {})
    document_id = payload.get("document_id")
    if not document_id:
        logger.error("Job %s missing document_id", item_id)
        await broker.fail(item_id)
        return

    try:
        logger.info("Processing document %s", document_id)
        try:
            await update_status(doc_client, document_id, "preprocessing")
        except Exception:  # noqa: BLE001
            logger.exception("Failed to mark document %s as preprocessing", document_id)
        original_bytes = await fetch_original(doc_client, document_id)
        processed_bytes = preprocess_image(original_bytes)
        await upload_preprocessed(doc_client, document_id, processed_bytes)
        await broker.ack(item_id)
        logger.info("Document %s preprocessed", document_id)
    except Exception as exc:  # noqa: BLE001
        logger.exception("Failed to preprocess document %s", document_id)
        await broker.fail(item_id)
        try:
            await mark_failed(doc_client, document_id, str(exc))
        except Exception:  # noqa: BLE001
            logger.exception("Failed to mark document %s as failed", document_id)


async def run_worker() -> None:
    broker = AsyncBrokerClient(settings.broker_service_url)
    async with httpx.AsyncClient(base_url=settings.document_service_url, timeout=20.0) as doc_client:
        try:
            while True:
                job = await broker.claim(settings.queue_topic)
                if job is None:
                    await asyncio.sleep(1.0)
                    continue
                await process_job(broker, doc_client, job)
        finally:
            await broker.close()


def main() -> None:
    asyncio.run(run_worker())


if __name__ == "__main__":
    main()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\src\main.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\src\core\config.py ---
import os
from dataclasses import dataclass


@dataclass(frozen=True)
class Settings:
    service_name: str = os.getenv("SERVICE_NAME", "image-preprocessing-service")
    broker_service_url: str = os.getenv("BROKER_SERVICE_URL", "http://broker-service:8003")
    document_service_url: str = os.getenv("DOCUMENT_SERVICE_URL", "http://document-service:8002")
    queue_topic: str = os.getenv("QUEUE_TOPIC", "image_preprocess")


def get_settings() -> Settings:
    return Settings()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\src\core\config.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\src\pipelines\preprocess.py ---
import cv2
import numpy as np


def preprocess_image(image_bytes: bytes) -> bytes:
    np_array = np.frombuffer(image_bytes, dtype=np.uint8)
    image = cv2.imdecode(np_array, cv2.IMREAD_COLOR)
    if image is None:
        return image_bytes

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (3, 3), 0)
    sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
    sharpened = cv2.filter2D(blurred, -1, sharpen_kernel)

    success, encoded = cv2.imencode(".png", sharpened)
    if not success:
        return image_bytes
    return encoded.tobytes()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\image-preprocessing-service\src\pipelines\preprocess.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\Dockerfile ---
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app:/app/shared

COPY processing-services/ocr-service/requirements.txt ./requirements.txt
RUN apt-get update && apt-get install -y --no-install-recommends \
    libgl1 \
    && rm -rf /var/lib/apt/lists/*
RUN pip install --no-cache-dir -r requirements.txt

COPY processing-services/ocr-service/src ./src
COPY shared/python ./shared

CMD ["python", "-m", "src.main"]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\Dockerfile ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\requirements.txt ---
torch==2.3.1
transformers==4.43.3
sentencepiece==0.2.0
httpx==0.27.0
orjson==3.10.7
Pillow==10.4.0
protobuf==4.25.3
--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\requirements.txt ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\src\main.py ---
from __future__ import annotations

import asyncio
import logging
from typing import Any

import httpx

from shared.utils.broker import AsyncBrokerClient

from .core.config import get_settings
from .pipelines.ocr import run_ocr

logger = logging.getLogger("ocr-service")
logging.basicConfig(level=logging.INFO)

settings = get_settings()


async def fetch_preprocessed(client: httpx.AsyncClient, document_id: str) -> bytes:
    response = await client.get(
        f"/api/internal/documents/{document_id}/binary",
        params={"variant": "preprocessed"},
    )
    response.raise_for_status()
    return response.content


async def upload_ocr_text(client: httpx.AsyncClient, document_id: str, text: str) -> None:
    response = await client.post(
        f"/api/internal/documents/{document_id}/ocr-text",
        json={"text": text},
    )
    response.raise_for_status()


async def update_status(client: httpx.AsyncClient, document_id: str, status_value: str) -> None:
    response = await client.post(
        f"/api/internal/documents/{document_id}/status",
        json={"status": status_value},
    )
    response.raise_for_status()


async def mark_failed(client: httpx.AsyncClient, document_id: str, message: str) -> None:
    response = await client.post(
        f"/api/internal/documents/{document_id}/fail",
        json={"error_message": message},
    )
    response.raise_for_status()


async def process_job(
    broker: AsyncBrokerClient,
    doc_client: httpx.AsyncClient,
    job: dict[str, Any],
) -> None:
    item_id = job["id"]
    payload = job.get("payload", {})
    document_id = payload.get("document_id")
    if not document_id:
        logger.error("Job %s missing document_id", item_id)
        await broker.fail(item_id)
        return

    try:
        logger.info("Running OCR for document %s", document_id)
        try:
            await update_status(doc_client, document_id, "ocr")
        except Exception:  # noqa: BLE001
            logger.exception("Failed to mark document %s as OCR in-progress", document_id)
        image_bytes = await fetch_preprocessed(doc_client, document_id)
        text = run_ocr(image_bytes)
        await upload_ocr_text(doc_client, document_id, text)
        await broker.ack(item_id)
        logger.info("Document %s OCR completed", document_id)
    except Exception as exc:  # noqa: BLE001
        logger.exception("Failed to run OCR for document %s", document_id)
        await broker.fail(item_id)
        try:
            await mark_failed(doc_client, document_id, str(exc))
        except Exception:  # noqa: BLE001
            logger.exception("Failed to mark document %s as failed", document_id)


async def run_worker() -> None:
    broker = AsyncBrokerClient(settings.broker_service_url)
    async with httpx.AsyncClient(base_url=settings.document_service_url, timeout=60.0) as doc_client:
        try:
            while True:
                job = await broker.claim(settings.queue_topic)
                if job is None:
                    await asyncio.sleep(1.0)
                    continue
                await process_job(broker, doc_client, job)
        finally:
            await broker.close()


def main() -> None:
    asyncio.run(run_worker())


if __name__ == "__main__":
    main()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\src\main.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\src\core\config.py ---
import os
from dataclasses import dataclass


@dataclass(frozen=True)
class Settings:
    service_name: str = os.getenv("SERVICE_NAME", "ocr-service")
    broker_service_url: str = os.getenv("BROKER_SERVICE_URL", "http://broker-service:8003")
    document_service_url: str = os.getenv("DOCUMENT_SERVICE_URL", "http://document-service:8002")
    queue_topic: str = os.getenv("QUEUE_TOPIC", "ocr_extract")
    model_name: str = os.getenv("OCR_MODEL_NAME", "microsoft/trocr-small-printed")


def get_settings() -> Settings:
    return Settings()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\src\core\config.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\src\pipelines\ocr.py ---
from __future__ import annotations

from functools import lru_cache
from typing import Any

from PIL import Image
import io
from transformers import TrOCRProcessor, VisionEncoderDecoderModel

from ..core.config import get_settings

settings = get_settings()


@lru_cache(maxsize=1)
def get_model() -> tuple[TrOCRProcessor, VisionEncoderDecoderModel]:
    processor = TrOCRProcessor.from_pretrained(settings.model_name)
    model = VisionEncoderDecoderModel.from_pretrained(settings.model_name)
    return processor, model


def run_ocr(image_bytes: bytes) -> str:
    processor, model = get_model()
    # Asigurm c imaginea este n format RGB (3 canale)
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    pixel_values = processor(images=image, return_tensors="pt").pixel_values
    generated_ids = model.generate(pixel_values)
    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return text.strip()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\processing-services\ocr-service\src\pipelines\ocr.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\Dockerfile ---
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app:/app/shared

COPY services/broker-service/requirements.txt ./requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

COPY services/broker-service/src ./src
COPY services/broker-service/migrations ./migrations
COPY services/broker-service/alembic.ini ./alembic.ini
COPY infrastructure/broker/definitions.json ./definitions.json
COPY shared/python ./shared

COPY entrypoint.sh ./entrypoint.sh
RUN chmod +x ./entrypoint.sh

ENTRYPOINT ["/app/entrypoint.sh"]

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8003"]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\Dockerfile ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\requirements.txt ---
fastapi==0.111.0
uvicorn[standard]==0.30.1
sqlalchemy[asyncio]==2.0.31
asyncpg==0.29.0
alembic==1.13.2
pydantic[email]==2.9.1
orjson==3.10.7

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\requirements.txt ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\migrations\env.py ---
import asyncio
from logging.config import fileConfig

from sqlalchemy import pool
from sqlalchemy.ext.asyncio import async_engine_from_config

from alembic import context

from src.core.config import get_settings
from src.db import models

# --- Alembic configuration ---
config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

settings = get_settings()
if not config.get_main_option("sqlalchemy.url"):
    config.set_main_option("sqlalchemy.url", settings.postgres_dsn)

target_metadata = models.Base.metadata
VERSION_TABLE = "alembic_version_broker"


def run_migrations_offline() -> None:
    """Run migrations in offline mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        version_table=VERSION_TABLE,
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection) -> None:
    """Execute migrations inside a sync connection."""
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        version_table=VERSION_TABLE,
    )
    with context.begin_transaction():
        context.run_migrations()


async def run_migrations_online() -> None:
    """Run migrations in online (async) mode."""
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


if context.is_offline_mode():
    run_migrations_offline()
else:
    asyncio.run(run_migrations_online())

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\migrations\env.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\migrations\versions\0001_create_queue_items.py ---
"""create queue items table

Revision ID: 0001_create_queue_items
Revises: 
Create Date: 2025-10-26
"""

from __future__ import annotations

import sqlalchemy as sa
from alembic import op


# revision identifiers, used by Alembic.
revision = "0001_create_queue_items"
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    op.execute("CREATE SCHEMA IF NOT EXISTS broker")
    op.create_table(
        "queue_items",
        sa.Column("id", sa.dialects.postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text("gen_random_uuid()")),
        sa.Column("topic", sa.String(length=64), nullable=False),
        sa.Column("payload", sa.Text(), nullable=False),
        sa.Column("status", sa.String(length=32), nullable=False, server_default="pending"),
        sa.Column("attempts", sa.Integer(), nullable=False, server_default=sa.text("0")),
        sa.Column("available_at", sa.DateTime(), nullable=False, server_default=sa.text("now()")),
        sa.Column("claimed_until", sa.DateTime(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False, server_default=sa.text("now()")),
        sa.Column("updated_at", sa.DateTime(), nullable=False, server_default=sa.text("now()")),
        schema="broker",
    )
    op.create_index("ix_queue_items_topic_status", "queue_items", ["topic", "status"], schema="broker")


def downgrade() -> None:
    op.drop_index("ix_queue_items_topic_status", table_name="queue_items", schema="broker")
    op.drop_table("queue_items", schema="broker")

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\migrations\versions\0001_create_queue_items.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\main.py ---
from fastapi import FastAPI

from .api.routes import router as api_router
from .core.config import get_settings

settings = get_settings()
app = FastAPI(title="Broker Service", version="0.1.0")
app.include_router(api_router, prefix="/api")


@app.get("/health", tags=["system"])
async def health() -> dict[str, str]:
    return {"status": "ok", "service": settings.service_name}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\main.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\api\routes.py ---
from __future__ import annotations

import json
from typing import Any

from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession

from ..core.config import get_settings
from ..db.session import get_session
from ..queue import manager

router = APIRouter()
settings = get_settings()


def get_topic_definition(topic: str) -> dict[str, Any]:
    definitions = settings.load_topic_definitions()
    return definitions.get(topic, {"max_retries": 5, "retry_delay_seconds": 30})


@router.get("/health", tags=["system"])
async def healthcheck() -> dict[str, str]:
    return {"status": "ok"}


@router.post("/enqueue/{topic}", tags=["queue"])
async def enqueue_topic(
    topic: str,
    payload: dict[str, Any],
    session: AsyncSession = Depends(get_session),
) -> dict[str, Any]:
    data = json.dumps(payload)
    item = await manager.enqueue(session, topic, data)
    await session.commit()
    return {"id": str(item.id), "topic": item.topic}


@router.post("/claim/{topic}", tags=["queue"])
async def claim_topic(topic: str, session: AsyncSession = Depends(get_session)) -> dict[str, Any]:
    item = await manager.claim(session, topic)
    if item is None:
        await session.commit()
        raise HTTPException(status_code=404, detail="no messages")
    await session.commit()
    return {
        "id": str(item.id),
        "topic": item.topic,
        "payload": json.loads(item.payload),
        "attempts": item.attempts,
    }


@router.post("/ack/{item_id}", tags=["queue"])
async def ack_item(item_id: str, session: AsyncSession = Depends(get_session)) -> dict[str, str]:
    success = await manager.ack(session, item_id)
    await session.commit()
    if not success:
        raise HTTPException(status_code=404, detail="item not found")
    return {"status": "acknowledged"}


@router.post("/fail/{item_id}", tags=["queue"])
async def fail_item(item_id: str, session: AsyncSession = Depends(get_session)) -> dict[str, str]:
    item = await manager.get_item(session, item_id)
    if item is None:
        await session.commit()
        raise HTTPException(status_code=404, detail="item not found")

    definition = get_topic_definition(item.topic)
    success = await manager.fail(session, item_id, retry_delay_seconds=definition.get("retry_delay_seconds", 30))
    await session.commit()
    return {"status": "requeued"}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\api\routes.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\core\config.py ---
import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any


@dataclass(frozen=True)
class Settings:
    service_name: str = os.getenv("SERVICE_NAME", "broker-service")
    postgres_dsn: str = os.getenv("POSTGRES_DSN", "postgresql+asyncpg://ocr_admin:ocr_admin@postgres:5432/ocr_platform")
    visibility_timeout_seconds: int = int(os.getenv("VISIBILITY_TIMEOUT_SECONDS", "120"))
    job_lease_seconds: int = int(os.getenv("JOB_LEASE_SECONDS", "60"))
    cleanup_interval_seconds: int = int(os.getenv("CLEANUP_INTERVAL_SECONDS", "30"))
    definitions_path: Path = Path(os.getenv("BROKER_DEFINITIONS_PATH", "/app/definitions.json"))

    def load_topic_definitions(self) -> dict[str, Any]:
        if not self.definitions_path.exists():
            return {}
        with self.definitions_path.open("r", encoding="utf-8") as fp:
            data = json.load(fp)
        topics = {item["name"]: item for item in data.get("topics", [])}
        return topics


def get_settings() -> Settings:
    return Settings()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\core\config.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\db\models.py ---
from __future__ import annotations

from datetime import datetime, timedelta
from uuid import uuid4

from sqlalchemy import Column, DateTime, Integer, String, Text
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import DeclarativeBase


class Base(DeclarativeBase):
    pass


class QueueItem(Base):
    __tablename__ = "queue_items"
    __table_args__ = {"schema": "broker"}

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid4)
    topic = Column(String(64), nullable=False, index=True)
    payload = Column(Text, nullable=False)
    status = Column(String(32), nullable=False, default="pending")
    attempts = Column(Integer, nullable=False, default=0)
    available_at = Column(DateTime, nullable=False, default=datetime.utcnow)
    claimed_until = Column(DateTime, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False)

    def claim(self, visibility_timeout_seconds: int) -> None:
        self.status = "processing"
        now = datetime.utcnow()
        self.claimed_until = now + timedelta(seconds=visibility_timeout_seconds)
        self.updated_at = now
        self.attempts += 1

    def mark_pending(self, *, delay_seconds: int = 0) -> None:
        now = datetime.utcnow()
        self.status = "pending"
        self.claimed_until = None
        self.available_at = now + timedelta(seconds=delay_seconds)
        self.updated_at = now

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\db\models.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\db\session.py ---
from __future__ import annotations

from collections.abc import AsyncGenerator

from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine

from ..core.config import get_settings

settings = get_settings()
engine = create_async_engine(settings.postgres_dsn, echo=False, future=True)
SessionLocal = async_sessionmaker(engine, expire_on_commit=False, class_=AsyncSession)


async def get_session() -> AsyncGenerator[AsyncSession, None]:
    async with SessionLocal() as session:
        yield session

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\db\session.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\queue\manager.py ---
from __future__ import annotations

from datetime import datetime
from typing import Optional

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from ..core.config import get_settings
from ..db.models import QueueItem

settings = get_settings()


async def enqueue(session: AsyncSession, topic: str, payload: str) -> QueueItem:
    item = QueueItem(topic=topic, payload=payload)
    session.add(item)
    await session.flush()
    return item


async def claim(session: AsyncSession, topic: str) -> Optional[QueueItem]:
    now = datetime.utcnow()
    stmt = (
        select(QueueItem)
        .where(QueueItem.topic == topic)
        .where(QueueItem.status == "pending")
        .where(QueueItem.available_at <= now)
        .order_by(QueueItem.created_at.asc())
        .limit(1)
        .with_for_update(skip_locked=True)
    )
    result = await session.execute(stmt)
    item = result.scalar_one_or_none()
    if item is None:
        return None
    item.claim(settings.visibility_timeout_seconds)
    return item


async def get_item(session: AsyncSession, item_id: str) -> Optional[QueueItem]:
    stmt = select(QueueItem).where(QueueItem.id == item_id)
    result = await session.execute(stmt)
    return result.scalar_one_or_none()


async def ack(session: AsyncSession, item_id: str) -> bool:
    item = await get_item(session, item_id)
    if item is None:
        return False
    await session.delete(item)
    return True


async def fail(session: AsyncSession, item_id: str, *, retry_delay_seconds: int) -> bool:
    item = await get_item(session, item_id)
    if item is None:
        return False
    item.mark_pending(delay_seconds=retry_delay_seconds)
    return True

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\broker-service\src\queue\manager.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\Dockerfile ---
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app:/app/shared

COPY services/document-service/requirements.txt ./requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

COPY services/document-service/src ./src
COPY services/document-service/migrations ./migrations
COPY services/document-service/alembic.ini ./alembic.ini
COPY shared/python ./shared

COPY entrypoint.sh ./entrypoint.sh
RUN chmod +x ./entrypoint.sh

ENTRYPOINT ["/app/entrypoint.sh"]

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8002"]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\Dockerfile ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\requirements.txt ---
fastapi==0.111.0
uvicorn[standard]==0.30.1
sqlalchemy[asyncio]==2.0.31
asyncpg==0.29.0
alembic==1.13.2
pydantic[email]==2.9.1
python-multipart==0.0.9
orjson==3.10.7
httpx==0.27.0

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\requirements.txt ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\migrations\env.py ---
import asyncio
from logging.config import fileConfig

from sqlalchemy import pool
from sqlalchemy.ext.asyncio import async_engine_from_config

from alembic import context

from src.core.config import get_settings
from src.db import models

# --- Alembic configuration ---
config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

settings = get_settings()
if not config.get_main_option("sqlalchemy.url"):
    config.set_main_option("sqlalchemy.url", settings.postgres_dsn)

target_metadata = models.Base.metadata
VERSION_TABLE = "alembic_version_documents"


def run_migrations_offline() -> None:
    """Run migrations in offline mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        version_table=VERSION_TABLE,
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection) -> None:
    """Execute migrations inside a sync connection."""
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        version_table=VERSION_TABLE,
    )
    with context.begin_transaction():
        context.run_migrations()


async def run_migrations_online() -> None:
    """Run migrations in online (async) mode."""
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


if context.is_offline_mode():
    run_migrations_offline()
else:
    asyncio.run(run_migrations_online())

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\migrations\env.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\migrations\versions\0001_create_documents_tables.py ---
"""create document tables

Revision ID: 0001_create_documents_tables
Revises: 
Create Date: 2025-10-26
"""

from __future__ import annotations

import sqlalchemy as sa
from alembic import op


# revision identifiers, used by Alembic.
revision = "0001_create_documents_tables"
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    op.create_table(
        "documents",
        sa.Column("id", sa.dialects.postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text("gen_random_uuid()")),
        sa.Column("owner_id", sa.String(length=64), nullable=False, index=True),
        sa.Column("filename", sa.String(length=255), nullable=False),
        sa.Column("content_type", sa.String(length=128), nullable=False),
        sa.Column("size_bytes", sa.Integer(), nullable=False),
        sa.Column("status", sa.String(length=32), nullable=False, server_default="uploaded"),
        sa.Column("ocr_text", sa.Text(), nullable=True),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False, server_default=sa.text("now()")),
        sa.Column("updated_at", sa.DateTime(), nullable=False, server_default=sa.text("now()")),
    )
    op.create_index("ix_documents_owner", "documents", ["owner_id"])

    op.create_table(
        "document_binaries",
        sa.Column("id", sa.dialects.postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text("gen_random_uuid()")),
        sa.Column("document_id", sa.dialects.postgresql.UUID(as_uuid=True), nullable=False, index=True),
        sa.Column("variant", sa.String(length=32), nullable=False),
        sa.Column("content", sa.LargeBinary(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False, server_default=sa.text("now()")),
    )
    op.create_unique_constraint(
        "uq_document_binaries_document_variant",
        "document_binaries",
        ["document_id", "variant"],
    )


def downgrade() -> None:
    op.drop_constraint("uq_document_binaries_document_variant", "document_binaries")
    op.drop_table("document_binaries")
    op.drop_index("ix_documents_owner", table_name="documents")
    op.drop_table("documents")

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\migrations\versions\0001_create_documents_tables.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\main.py ---
from fastapi import FastAPI

from .api.routes import router as api_router
from .core.config import get_settings

settings = get_settings()
app = FastAPI(title="Document Service", version="0.1.0")
app.include_router(api_router, prefix="/api")


@app.get("/health", tags=["system"])
async def health() -> dict[str, str]:
    return {"status": "ok", "service": settings.service_name}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\main.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\api\routes.py ---
from __future__ import annotations

import base64
from collections.abc import AsyncGenerator
from datetime import datetime
from typing import Any, Optional

from fastapi import APIRouter, Depends, File, Header, HTTPException, Response, UploadFile, status
from sqlalchemy.ext.asyncio import AsyncSession

from ..clients.broker_client import BrokerClient
from ..core.config import get_settings
from ..db.session import get_session
from ..repositories import documents as documents_repo
from ..schemas.document import (
    BinaryPayload,
    BinaryVariant,
    DocumentRead,
    FailurePayload,
    OCRTextPayload,
    StatusUpdatePayload,
)
from shared.schemas.events import DocumentEvent, DocumentEventType

settings = get_settings()
router = APIRouter()


async def get_owner_id(x_user_id: Optional[str] = Header(default=None)) -> str:
    if not x_user_id:
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="missing user context")
    return x_user_id


async def get_broker_client() -> AsyncGenerator[BrokerClient, None]:
    client = BrokerClient(settings.broker_service_url)
    try:
        yield client
    finally:
        await client.close()


async def _publish_event(
    broker: BrokerClient,
    *,
    event_type: DocumentEventType,
    document_id: str,
    owner_id: str,
    payload: Optional[dict[str, Any]] = None,
) -> None:
    event = DocumentEvent(
        event_type=event_type,
        document_id=document_id,
        owner_id=owner_id,
        timestamp=datetime.utcnow(),
        payload=payload,
    )
    await broker.enqueue("document_events", event.model_dump(mode="json"))


@router.get("/health", tags=["system"])
async def healthcheck() -> dict[str, str]:
    return {"status": "ok"}


@router.post("/documents", response_model=DocumentRead, status_code=status.HTTP_201_CREATED, tags=["documents"])
async def upload_document(
    file: UploadFile = File(...),
    owner_id: str = Depends(get_owner_id),
    session: AsyncSession = Depends(get_session),
    broker: BrokerClient = Depends(get_broker_client),
) -> DocumentRead:
    content = await file.read()
    if not content:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="empty file")

    max_bytes = settings.max_upload_mb * 1024 * 1024
    if len(content) > max_bytes:
        raise HTTPException(status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE, detail="file too large")

    try:
        document = await documents_repo.create_document(
            session,
            owner_id=owner_id,
            filename=file.filename or "upload",
            content_type=file.content_type or "application/octet-stream",
            size_bytes=len(content),
        )
        await documents_repo.store_binary(
            session,
            document_id=str(document.id),
            variant="original",
            content=content,
        )
        # Documentul este doar ncrcat, nu trimis la procesare
        document.status = "uploaded"
        await session.commit()
        return DocumentRead.model_validate(document)
    except HTTPException:
        await session.rollback()
        raise
    except Exception as exc:  # noqa: BLE001
        await session.rollback()
        raise HTTPException(status_code=500, detail="failed to upload document") from exc


@router.get("/documents", response_model=list[DocumentRead], tags=["documents"])
async def list_documents(
    owner_id: str = Depends(get_owner_id),
    session: AsyncSession = Depends(get_session),
) -> list[DocumentRead]:
    items = await documents_repo.list_documents(session, owner_id)
    return [DocumentRead.model_validate(item) for item in items]


async def _get_owned_document_or_404(
    session: AsyncSession,
    *,
    document_id: str,
    owner_id: str,
) -> DocumentRead:
    document = await documents_repo.get_document(session, document_id)
    if document is None or document.owner_id != owner_id:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="document not found")
    return DocumentRead.model_validate(document)


@router.get("/documents/{document_id}", response_model=DocumentRead, tags=["documents"])
async def get_document(
    document_id: str,
    owner_id: str = Depends(get_owner_id),
    session: AsyncSession = Depends(get_session),
) -> DocumentRead:
    return await _get_owned_document_or_404(session, document_id=document_id, owner_id=owner_id)


# Return an explicit empty response for delete semantics.
@router.delete(
    "/documents/{document_id}",
    status_code=status.HTTP_204_NO_CONTENT,
    tags=["documents"],
    response_class=Response,
)
async def delete_document(
    document_id: str,
    owner_id: str = Depends(get_owner_id),
    session: AsyncSession = Depends(get_session),
) -> Response:
    await _get_owned_document_or_404(session, document_id=document_id, owner_id=owner_id)
    await documents_repo.delete_document(session, document_id)
    await session.commit()
    return Response(status_code=status.HTTP_204_NO_CONTENT)


@router.post("/documents/{document_id}/process", response_model=DocumentRead, tags=["documents"])
async def requeue_document(
    document_id: str,
    owner_id: str = Depends(get_owner_id),
    session: AsyncSession = Depends(get_session),
    broker: BrokerClient = Depends(get_broker_client),
) -> DocumentRead:
    document = await documents_repo.get_document(session, document_id)
    if document is None or document.owner_id != owner_id:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="document not found")

    try:
        document.status = "queued_preprocessing"
        document.error_message = None
        document.ocr_text = None
        await session.flush()

        await _publish_event(
            broker,
            event_type="document_uploaded",
            document_id=str(document.id),
            owner_id=owner_id,
            payload={"reason": "manual_requeue"},
        )
        await session.commit()
        await session.refresh(document)
        return DocumentRead.model_validate(document)
    except HTTPException:
        await session.rollback()
        raise
    except Exception as exc:  # noqa: BLE001
        await session.rollback()
        raise HTTPException(status_code=500, detail="failed to requeue document") from exc


def _decode_base64(data_base64: str) -> bytes:
    try:
        return base64.b64decode(data_base64, validate=True)
    except Exception as exc:  # noqa: BLE001
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="invalid base64 payload") from exc


@router.get(
    "/internal/documents/{document_id}/binary",
    response_class=Response,
    tags=["internal"],
)
async def get_binary(
    document_id: str,
    variant: BinaryVariant = "original",
    session: AsyncSession = Depends(get_session),
) -> Response:
    record = await documents_repo.get_binary(session, document_id=document_id, variant=variant)
    if record is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="binary not found")
    media_type = "application/octet-stream" if variant != "preprocessed" else "image/png"
    return Response(content=record.content, media_type=media_type)


@router.post(
    "/internal/documents/{document_id}/binary",
    status_code=status.HTTP_204_NO_CONTENT,
    tags=["internal"],
    response_class=Response,
)
async def upload_variant(
    document_id: str,
    payload: BinaryPayload,
    session: AsyncSession = Depends(get_session),
    broker: BrokerClient = Depends(get_broker_client),
) -> Response:
    document = await documents_repo.get_document(session, document_id)
    if document is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="document not found")

    try:
        content = _decode_base64(payload.data_base64)
        await documents_repo.store_binary(
            session,
            document_id=document_id,
            variant=payload.variant,
            content=content,
        )

        if payload.variant == "preprocessed":
            document.status = "queued_ocr"
            document.error_message = None
            await session.flush()
            await _publish_event(
                broker,
                event_type="document_preprocessed",
                document_id=document_id,
                owner_id=document.owner_id,
                payload={"variant": payload.variant},
            )

        await session.commit()
        return Response(status_code=status.HTTP_204_NO_CONTENT)
    except HTTPException:
        await session.rollback()
        raise
    except Exception as exc:  # noqa: BLE001
        await session.rollback()
        raise HTTPException(status_code=500, detail="failed to store binary variant") from exc


@router.post(
    "/internal/documents/{document_id}/status",
    status_code=status.HTTP_204_NO_CONTENT,
    tags=["internal"],
    response_class=Response,
)
async def update_document_status(
    document_id: str,
    payload: StatusUpdatePayload,
    session: AsyncSession = Depends(get_session),
) -> Response:
    document = await documents_repo.get_document(session, document_id)
    if document is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="document not found")

    try:
        await documents_repo.update_status(
            session,
            document_id=document_id,
            status=payload.status,
            error_message=payload.error_message,
            ocr_text=payload.ocr_text,
        )
        await session.commit()
        return Response(status_code=status.HTTP_204_NO_CONTENT)
    except HTTPException:
        await session.rollback()
        raise
    except Exception as exc:  # noqa: BLE001
        await session.rollback()
        raise HTTPException(status_code=500, detail="failed to update document status") from exc


@router.post(
    "/internal/documents/{document_id}/ocr-text",
    status_code=status.HTTP_204_NO_CONTENT,
    tags=["internal"],
    response_class=Response,
)
async def upload_ocr_text(
    document_id: str,
    payload: OCRTextPayload,
    session: AsyncSession = Depends(get_session),
    broker: BrokerClient = Depends(get_broker_client),
) -> Response:
    document = await documents_repo.get_document(session, document_id)
    if document is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="document not found")

    try:
        document.status = "completed"
        document.ocr_text = payload.text
        document.error_message = None
        await session.flush()
        await _publish_event(
            broker,
            event_type="document_ocr_completed",
            document_id=document_id,
            owner_id=document.owner_id,
            payload={
                "characters": len(payload.text),
                "preview": payload.text[:200],
            },
        )
        await session.commit()
        return Response(status_code=status.HTTP_204_NO_CONTENT)
    except HTTPException:
        await session.rollback()
        raise
    except Exception as exc:  # noqa: BLE001
        await session.rollback()
        raise HTTPException(status_code=500, detail="failed to persist OCR text") from exc


@router.post(
    "/internal/documents/{document_id}/fail",
    status_code=status.HTTP_204_NO_CONTENT,
    tags=["internal"],
    response_class=Response,
)
async def mark_document_failed(
    document_id: str,
    payload: FailurePayload,
    session: AsyncSession = Depends(get_session),
    broker: BrokerClient = Depends(get_broker_client),
) -> Response:
    document = await documents_repo.get_document(session, document_id)
    if document is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="document not found")

    try:
        document.status = "failed"
        document.error_message = payload.error_message
        await session.flush()
        await _publish_event(
            broker,
            event_type="document_failed",
            document_id=document_id,
            owner_id=document.owner_id,
            payload={"error_message": payload.error_message},
        )
        await session.commit()
        return Response(status_code=status.HTTP_204_NO_CONTENT)
    except HTTPException:
        await session.rollback()
        raise
    except Exception as exc:  # noqa: BLE001
        await session.rollback()
        raise HTTPException(status_code=500, detail="failed to mark document as failed") from exc

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\api\routes.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\clients\broker_client.py ---
from shared.utils.broker import AsyncBrokerClient as BrokerClient

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\clients\broker_client.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\core\config.py ---
import os
from dataclasses import dataclass


@dataclass(frozen=True)
class Settings:
    service_name: str = os.getenv("SERVICE_NAME", "document-service")
    postgres_dsn: str = os.getenv("POSTGRES_DSN", "postgresql+asyncpg://ocr_admin:ocr_admin@postgres:5432/ocr_platform")
    broker_service_url: str = os.getenv("BROKER_SERVICE_URL", "http://broker-service:8003")
    storage_backend: str = os.getenv("STORAGE_BACKEND", "postgres")
    max_upload_mb: int = int(os.getenv("MAX_UPLOAD_MB", "10"))


def get_settings() -> Settings:
    return Settings()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\core\config.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\db\models.py ---
from __future__ import annotations

from datetime import datetime
from uuid import uuid4

from sqlalchemy import Column, DateTime, LargeBinary, Integer, String, Text
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import DeclarativeBase


class Base(DeclarativeBase):
    pass


class Document(Base):
    __tablename__ = "documents"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid4)
    owner_id = Column(String(64), nullable=False, index=True)
    filename = Column(String(255), nullable=False)
    content_type = Column(String(128), nullable=False)
    size_bytes = Column(Integer, nullable=False)
    status = Column(String(32), nullable=False, default="uploaded")
    ocr_text = Column(Text, nullable=True)
    error_message = Column(Text, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False)


class DocumentBinary(Base):
    __tablename__ = "document_binaries"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid4)
    document_id = Column(UUID(as_uuid=True), nullable=False, index=True)
    variant = Column(String(32), nullable=False)  # original, preprocessed
    content = Column(LargeBinary, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\db\models.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\db\session.py ---
from __future__ import annotations

from collections.abc import AsyncGenerator

from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine

from ..core.config import get_settings

settings = get_settings()
engine = create_async_engine(settings.postgres_dsn, echo=False, future=True)
SessionLocal = async_sessionmaker(engine, expire_on_commit=False, class_=AsyncSession)


async def get_session() -> AsyncGenerator[AsyncSession, None]:
    async with SessionLocal() as session:
        yield session

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\db\session.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\repositories\documents.py ---
from __future__ import annotations

from __future__ import annotations

from datetime import datetime
from typing import Iterable, Optional

from sqlalchemy import Select, delete, select, update
from sqlalchemy.ext.asyncio import AsyncSession

from ..db.models import Document, DocumentBinary


async def get_document(session: AsyncSession, document_id: str) -> Optional[Document]:
    stmt = select(Document).where(Document.id == document_id)
    result = await session.execute(stmt)
    return result.scalar_one_or_none()


async def list_documents(session: AsyncSession, owner_id: str) -> Iterable[Document]:
    stmt: Select[Document] = select(Document).where(Document.owner_id == owner_id).order_by(Document.created_at.desc())
    result = await session.execute(stmt)
    return result.scalars().all()


async def create_document(
    session: AsyncSession,
    *,
    owner_id: str,
    filename: str,
    content_type: str,
    size_bytes: int,
) -> Document:
    doc = Document(
        owner_id=owner_id,
        filename=filename,
        content_type=content_type,
        size_bytes=size_bytes,
        status="uploaded",
    )
    session.add(doc)
    await session.flush()
    await session.refresh(doc)
    return doc


async def store_binary(
    session: AsyncSession,
    *,
    document_id: str,
    variant: str,
    content: bytes,
) -> DocumentBinary:
    await session.execute(
        delete(DocumentBinary).where(
            DocumentBinary.document_id == document_id,
            DocumentBinary.variant == variant,
        )
    )
    record = DocumentBinary(document_id=document_id, variant=variant, content=content)
    session.add(record)
    await session.flush()
    return record


async def get_binary(session: AsyncSession, *, document_id: str, variant: str = "original") -> Optional[DocumentBinary]:
    stmt = select(DocumentBinary).where(
        DocumentBinary.document_id == document_id,
        DocumentBinary.variant == variant,
    )
    result = await session.execute(stmt)
    return result.scalar_one_or_none()


async def update_status(
    session: AsyncSession,
    *,
    document_id: str,
    status: str,
    error_message: Optional[str] = None,
    ocr_text: Optional[str] = None,
) -> None:
    values: dict[str, object] = {
        "status": status,
        "updated_at": datetime.utcnow(),
    }
    if error_message is not None:
        values["error_message"] = error_message
    if ocr_text is not None:
        values["ocr_text"] = ocr_text
    stmt = (
        update(Document)
        .where(Document.id == document_id)
        .values(**values)
        .execution_options(synchronize_session="fetch")
    )
    await session.execute(stmt)


async def delete_document(session: AsyncSession, document_id: str) -> None:
    await session.execute(delete(DocumentBinary).where(DocumentBinary.document_id == document_id))
    await session.execute(delete(Document).where(Document.id == document_id))

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\repositories\documents.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\schemas\document.py ---
from datetime import datetime
from typing import Literal, Optional
from uuid import UUID

from pydantic import BaseModel, Field

DocumentStatus = Literal[
    "uploaded",
    "queued_preprocessing",
    "preprocessing",
    "queued_ocr",
    "ocr",
    "completed",
    "failed",
]


class DocumentCreate(BaseModel):
    filename: str
    content_type: str
    size_bytes: int
    owner_id: str


class DocumentRead(BaseModel):
    id: UUID
    owner_id: str
    filename: str
    content_type: str
    size_bytes: int
    status: DocumentStatus
    error_message: Optional[str] = None
    created_at: datetime
    updated_at: datetime
    ocr_text: Optional[str] = Field(default=None, description="OCR output if available")

    class Config:
        from_attributes = True


BinaryVariant = Literal["original", "preprocessed"]


class BinaryPayload(BaseModel):
    variant: BinaryVariant
    data_base64: str = Field(..., description="Base64 encoded binary payload")


class OCRTextPayload(BaseModel):
    text: str


class FailurePayload(BaseModel):
    error_message: str


class StatusUpdatePayload(BaseModel):
    status: DocumentStatus
    error_message: Optional[str] = None
    ocr_text: Optional[str] = None

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\schemas\document.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\storage\__init__.py ---
from pathlib import Path

STORAGE_ROOT = Path("/tmp/documents")
STORAGE_ROOT.mkdir(parents=True, exist_ok=True)

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\document-service\src\storage\__init__.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\Dockerfile ---
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app:/app/shared

COPY services/user-service/requirements.txt ./requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

COPY services/user-service/src ./src
COPY services/user-service/migrations ./migrations
COPY services/user-service/alembic.ini ./alembic.ini
COPY shared/python ./shared

COPY entrypoint.sh ./entrypoint.sh
RUN chmod +x ./entrypoint.sh

ENTRYPOINT ["/app/entrypoint.sh"]

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8001"]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\Dockerfile ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\requirements.txt ---
fastapi==0.111.0
uvicorn[standard]==0.30.1
sqlalchemy[asyncio]==2.0.31
asyncpg==0.29.0
alembic==1.13.2
bcrypt==3.2.2
passlib[bcrypt]==1.7.4
python-jose[cryptography]==3.3.0
pydantic[email]==2.9.1
orjson==3.10.7

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\requirements.txt ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\migrations\env.py ---
import asyncio
from logging.config import fileConfig

from sqlalchemy import pool
from sqlalchemy.ext.asyncio import async_engine_from_config

from alembic import context

from src.core.config import get_settings
from src.db import models

# --- Alembic configuration ---
config = context.config

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

settings = get_settings()
if not config.get_main_option("sqlalchemy.url"):
    config.set_main_option("sqlalchemy.url", settings.postgres_dsn)

target_metadata = models.Base.metadata
VERSION_TABLE = "alembic_version_user"


def run_migrations_offline() -> None:
    """Run migrations in offline mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        version_table=VERSION_TABLE,
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection) -> None:
    """Execute migrations inside a sync connection."""
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        version_table=VERSION_TABLE,
    )
    with context.begin_transaction():
        context.run_migrations()


async def run_migrations_online() -> None:
    """Run migrations in online (async) mode."""
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


if context.is_offline_mode():
    run_migrations_offline()
else:
    asyncio.run(run_migrations_online())

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\migrations\env.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\migrations\versions\0001_create_users_table.py ---
"""create users table

Revision ID: 0001_create_users_table
Revises: 
Create Date: 2025-10-26
"""

from __future__ import annotations

import sqlalchemy as sa
from alembic import op


# revision identifiers, used by Alembic.
revision = "0001_create_users_table"
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    op.create_table(
        "users",
        sa.Column("id", sa.Integer(), primary_key=True),
        sa.Column("email", sa.String(length=320), nullable=False, unique=True),
        sa.Column("full_name", sa.String(length=255), nullable=False),
        sa.Column("password_hash", sa.String(length=255), nullable=False),
        sa.Column("refresh_token_hash", sa.String(length=255), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False, server_default=sa.text("now()")),
        sa.Column("updated_at", sa.DateTime(), nullable=False, server_default=sa.text("now()")),
    )
    op.create_index("ix_auth_users_email", "users", ["email"], unique=True)


def downgrade() -> None:
    op.drop_index("ix_auth_users_email", table_name="users")
    op.drop_table("users")

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\migrations\versions\0001_create_users_table.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\main.py ---
from fastapi import FastAPI

from .api.routes import router as api_router
from .core.config import get_settings

settings = get_settings()
app = FastAPI(title="User Service", version="0.1.0")
app.include_router(api_router, prefix="/api")


@app.get("/health", tags=["system"])
async def health() -> dict[str, str]:
    return {"status": "ok", "service": settings.service_name}

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\main.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\api\routes.py ---
from __future__ import annotations

from fastapi import APIRouter, Depends, HTTPException, Response, status
from sqlalchemy.ext.asyncio import AsyncSession

from ..core import auth
from ..db import crud
from ..db.session import get_session
from ..schemas.user import LoginRequest, RefreshRequest, TokenPair, UserCreate, UserRead

router = APIRouter()


@router.get("/health", tags=["system"])
async def healthcheck() -> dict[str, str]:
    return {"status": "ok"}


@router.post("/auth/register", response_model=UserRead, status_code=status.HTTP_201_CREATED, tags=["auth"])
async def register_user(
    payload: UserCreate,
    session: AsyncSession = Depends(get_session),
) -> UserRead:
    existing = await crud.get_user_by_email(session, payload.email)
    if existing:
        raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail="email already registered")
    password_hash = auth.hash_password(payload.password)
    user = await crud.create_user(
        session,
        email=payload.email,
        full_name=payload.full_name,
        password_hash=password_hash,
    )
    await session.commit()
    return UserRead.model_validate(user)


@router.post("/auth/login", response_model=TokenPair, tags=["auth"])
async def login_user(
    payload: LoginRequest,
    session: AsyncSession = Depends(get_session),
) -> TokenPair:
    user = await crud.get_user_by_email(session, payload.email)
    if user is None or not auth.verify_password(payload.password, user.password_hash):
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="invalid credentials")
    tokens = auth.generate_tokens(str(user.id))
    refresh_hash = auth.hash_password(tokens.refresh_token)
    await crud.update_refresh_token_hash(session, user_id=user.id, refresh_token_hash=refresh_hash)
    await session.commit()
    return TokenPair(access_token=tokens.access_token, refresh_token=tokens.refresh_token)


@router.post("/auth/refresh", response_model=TokenPair, tags=["auth"])
async def refresh_tokens(
    payload: RefreshRequest,
    session: AsyncSession = Depends(get_session),
) -> TokenPair:
    try:
        user_id = int(auth.decode_refresh_token(payload.refresh_token))
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="invalid token") from exc

    user = await crud.get_user_by_id(session, user_id)
    if user is None or not auth.verify_refresh_token(payload.refresh_token, user.refresh_token_hash):
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="invalid token")

    tokens = auth.generate_tokens(str(user.id))
    refresh_hash = auth.hash_password(tokens.refresh_token)
    await crud.update_refresh_token_hash(session, user_id=user.id, refresh_token_hash=refresh_hash)
    await session.commit()
    return TokenPair(access_token=tokens.access_token, refresh_token=tokens.refresh_token)


# FastAPI requires an explicit empty response for 204 endpoints.
@router.post("/auth/logout", status_code=status.HTTP_204_NO_CONTENT, tags=["auth"], response_class=Response)
async def logout_user(
    payload: RefreshRequest,
    session: AsyncSession = Depends(get_session),
) -> Response:
    try:
        user_id = int(auth.decode_refresh_token(payload.refresh_token))
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="invalid token") from exc

    user = await crud.get_user_by_id(session, user_id)
    if user is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="user not found")

    await crud.clear_refresh_token_hash(session, user_id=user.id)
    await session.commit()
    return Response(status_code=status.HTTP_204_NO_CONTENT)

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\api\routes.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\core\auth.py ---
from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime, timezone

from shared.utils.jwt import create_token, decode_token
from shared.utils.security import hash_secret, verify_secret

from .config import get_settings

settings = get_settings()


@dataclass(frozen=True)
class TokenPair:
    access_token: str
    refresh_token: str


def hash_password(raw_password: str) -> str:
    return hash_secret(raw_password)


def verify_password(raw_password: str, hashed_password: str) -> bool:
    return verify_secret(raw_password, hashed_password)


def generate_tokens(user_id: str) -> TokenPair:
    access = create_token(
        subject=user_id,
        secret_key=settings.jwt_secret_key,
        algorithm="HS256",
        ttl_seconds=settings.access_token_ttl_seconds,
        scope="access",
    )
    refresh = create_token(
        subject=user_id,
        secret_key=settings.jwt_secret_key,
        algorithm="HS256",
        ttl_seconds=settings.refresh_token_ttl_seconds,
        scope="refresh",
        extra_claims={"nonce": datetime.now(timezone.utc).timestamp()},
    )
    return TokenPair(access_token=access, refresh_token=refresh)


def decode_refresh_token(token: str) -> str:
    payload = decode_token(token=token, secret_key=settings.jwt_secret_key, algorithm="HS256")
    scope = payload.get("scope")
    if scope != "refresh":
        raise ValueError("invalid scope")
    return str(payload.get("sub"))


def verify_refresh_token(raw_refresh_token: str, stored_hash: str | None) -> bool:
    if not stored_hash:
        return False
    return verify_secret(raw_refresh_token, stored_hash)

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\core\auth.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\core\config.py ---
import os
from dataclasses import dataclass


@dataclass(frozen=True)
class Settings:
    service_name: str = os.getenv("SERVICE_NAME", "user-service")
    postgres_dsn: str = os.getenv("POSTGRES_DSN", "postgresql+asyncpg://ocr_admin:ocr_admin@postgres:5432/ocr_platform")
    jwt_secret_key: str = os.getenv("JWT_SECRET_KEY", "change-me")
    access_token_ttl_seconds: int = int(os.getenv("ACCESS_TOKEN_TTL_SECONDS", "900"))
    refresh_token_ttl_seconds: int = int(os.getenv("REFRESH_TOKEN_TTL_SECONDS", "604800"))


def get_settings() -> Settings:
    return Settings()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\core\config.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\db\crud.py ---
from __future__ import annotations

from typing import Optional

from sqlalchemy import select, update
from sqlalchemy.ext.asyncio import AsyncSession

from .models import User


async def get_user_by_email(session: AsyncSession, email: str) -> Optional[User]:
    stmt = select(User).where(User.email == email)
    result = await session.execute(stmt)
    return result.scalar_one_or_none()


async def get_user_by_id(session: AsyncSession, user_id: int) -> Optional[User]:
    stmt = select(User).where(User.id == user_id)
    result = await session.execute(stmt)
    return result.scalar_one_or_none()


async def create_user(session: AsyncSession, *, email: str, full_name: str, password_hash: str) -> User:
    user = User(email=email, full_name=full_name, password_hash=password_hash)
    session.add(user)
    await session.flush()
    await session.refresh(user)
    return user


async def update_refresh_token_hash(session: AsyncSession, *, user_id: int, refresh_token_hash: str) -> None:
    stmt = (
        update(User)
        .where(User.id == user_id)
        .values(refresh_token_hash=refresh_token_hash)
        .execution_options(synchronize_session="fetch")
    )
    await session.execute(stmt)


async def clear_refresh_token_hash(session: AsyncSession, *, user_id: int) -> None:
    stmt = (
        update(User)
        .where(User.id == user_id)
        .values(refresh_token_hash=None)
        .execution_options(synchronize_session="fetch")
    )
    await session.execute(stmt)

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\db\crud.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\db\models.py ---
from __future__ import annotations

from datetime import datetime
from typing import Optional

from sqlalchemy import Column, DateTime, Integer, String
from sqlalchemy.orm import DeclarativeBase


class Base(DeclarativeBase):
    pass


class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String(320), unique=True, nullable=False, index=True)
    full_name = Column(String(255), nullable=False)
    password_hash = Column(String(255), nullable=False)
    refresh_token_hash = Column(String(255), nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False)

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\db\models.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\db\session.py ---
from __future__ import annotations

from collections.abc import AsyncGenerator

from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine

from ..core.config import get_settings

settings = get_settings()
engine = create_async_engine(settings.postgres_dsn, echo=False, future=True)
SessionLocal = async_sessionmaker(engine, expire_on_commit=False, class_=AsyncSession)


async def get_session() -> AsyncGenerator[AsyncSession, None]:
    async with SessionLocal() as session:
        yield session

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\db\session.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\schemas\user.py ---
from datetime import datetime

from pydantic import BaseModel, EmailStr


class UserCreate(BaseModel):
    email: EmailStr
    password: str
    full_name: str


class UserRead(BaseModel):
    id: int
    email: EmailStr
    full_name: str
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True


class LoginRequest(BaseModel):
    email: EmailStr
    password: str


class RefreshRequest(BaseModel):
    refresh_token: str


class TokenPair(BaseModel):
    access_token: str
    refresh_token: str
    token_type: str = "bearer"

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\user-service\src\schemas\user.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\Dockerfile ---
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app:/app/shared

COPY services/worker-service/requirements.txt ./requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

COPY services/worker-service/src ./src
COPY shared/python ./shared

CMD ["python", "-m", "src.main"]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\Dockerfile ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\requirements.txt ---
httpx==0.27.0
pydantic[email]==2.9.1
orjson==3.10.7

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\requirements.txt ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\src\main.py ---
from __future__ import annotations

import asyncio
import logging

from shared.utils.broker import AsyncBrokerClient

from .consumers.document_consumer import DocumentConsumer
from .core.config import get_settings

logger = logging.getLogger("worker-service")
logging.basicConfig(level=logging.INFO)


async def run_worker() -> None:
    settings = get_settings()
    broker = AsyncBrokerClient(settings.broker_service_url)
    consumer = DocumentConsumer(broker, settings=settings)

    try:
        while True:
            try:
                job = await broker.claim(settings.document_events_topic)
            except Exception as exc:  # noqa: BLE001
                if isinstance(exc, asyncio.CancelledError):  # propagate cancellations cleanly
                    raise
                logger.exception("Failed to claim document event: %s", exc)
                await asyncio.sleep(settings.poll_interval_seconds)
                continue

            if job is None:
                await asyncio.sleep(settings.poll_interval_seconds)
                continue

            item_id = job["id"]
            try:
                await consumer.handle(job["payload"])
            except Exception as exc:  # noqa: BLE001
                if isinstance(exc, asyncio.CancelledError):
                    raise
                logger.exception("Error processing event %s: %s", item_id, exc)
                try:
                    await broker.fail(item_id)
                except Exception:  # noqa: BLE001
                    logger.exception("Failed to requeue event %s", item_id)
                await asyncio.sleep(settings.poll_interval_seconds)
                continue

            try:
                await broker.ack(item_id)
            except Exception as exc:  # noqa: BLE001
                if isinstance(exc, asyncio.CancelledError):
                    raise
                logger.exception("Failed to ack event %s", item_id)

    finally:
        await broker.close()


def main() -> None:
    asyncio.run(run_worker())


if __name__ == "__main__":
    main()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\src\main.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\src\consumers\document_consumer.py ---
from __future__ import annotations

import logging
from typing import Any, Awaitable, Callable, Dict

from shared.schemas.events import DocumentEvent, DocumentEventType
from shared.utils.broker import AsyncBrokerClient

from ..core.config import Settings
from ..publishers.ocr_publisher import publish_ocr_task

logger = logging.getLogger(__name__)


Handler = Callable[[DocumentEvent], Awaitable[None]]


class DocumentConsumer:
    """Handle document lifecycle events and dispatch next-step jobs."""

    def __init__(self, broker: AsyncBrokerClient, *, settings: Settings) -> None:
        self._broker = broker
        self._settings = settings
        self._handlers: Dict[DocumentEventType, Handler] = {
            "document_uploaded": self._handle_document_uploaded,
            "document_preprocessed": self._handle_document_preprocessed,
            "document_ocr_completed": self._handle_document_completed,
            "document_failed": self._handle_document_failed,
        }

    async def handle(self, payload: dict[str, Any]) -> None:
        event = DocumentEvent.model_validate(payload)
        handler = self._handlers.get(event.event_type)
        if handler is None:
            logger.warning("No handler registered for event '%s'", event.event_type)
            return
        await handler(event)

    async def _handle_document_uploaded(self, event: DocumentEvent) -> None:
        logger.info("Enqueueing preprocessing job for document %s", event.document_id)
        job_id = await self._broker.enqueue(
            self._settings.preprocess_topic,
            {
                "document_id": event.document_id,
                "owner_id": event.owner_id,
            },
        )
        logger.debug("Queued preprocessing item %s", job_id)

    async def _handle_document_preprocessed(self, event: DocumentEvent) -> None:
        logger.info("Enqueueing OCR job for document %s", event.document_id)
        job_id = await publish_ocr_task(
            self._broker,
            {
                "document_id": event.document_id,
                "owner_id": event.owner_id,
            },
            topic=self._settings.ocr_topic,
        )
        logger.debug("Queued OCR item %s", job_id)

    async def _handle_document_completed(self, event: DocumentEvent) -> None:
        logger.info("Document %s OCR completed", event.document_id)

    async def _handle_document_failed(self, event: DocumentEvent) -> None:
        logger.error(
            "Document %s failed to process: %s",
            event.document_id,
            (event.payload or {}).get("error_message", "unknown error"),
        )

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\src\consumers\document_consumer.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\src\core\config.py ---
import os
from dataclasses import dataclass


@dataclass(frozen=True)
class Settings:
    service_name: str = os.getenv("SERVICE_NAME", "worker-service")
    broker_service_url: str = os.getenv("BROKER_SERVICE_URL", "http://broker-service:8003")
    document_service_url: str = os.getenv("DOCUMENT_SERVICE_URL", "http://document-service:8002")
    poll_interval_seconds: float = float(os.getenv("POLL_INTERVAL_SECONDS", "2.0"))
    document_events_topic: str = os.getenv("DOCUMENT_EVENTS_TOPIC", "document_events")
    preprocess_topic: str = os.getenv("PREPROCESS_TOPIC", "image_preprocess")
    ocr_topic: str = os.getenv("OCR_TOPIC", "ocr_extract")


def get_settings() -> Settings:
    return Settings()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\src\core\config.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\src\publishers\ocr_publisher.py ---
from __future__ import annotations

from typing import Any

from shared.utils.broker import AsyncBrokerClient


async def publish_ocr_task(
    broker: AsyncBrokerClient,
    payload: dict[str, Any],
    *,
    topic: str = "ocr_extract",
) -> str:
    """Publish an OCR extraction task to the broker and return the queue item id."""

    return await broker.enqueue(topic, payload)

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\services\worker-service\src\publishers\ocr_publisher.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\config\logging.yaml ---
version: 1
formatters:
  standard:
    format: "%(asctime)s %(levelname)s [%(name)s] %(message)s"
handlers:
  console:
    class: logging.StreamHandler
    formatter: standard
    level: INFO
    stream: ext://sys.stdout
root:
  level: INFO
  handlers: [console]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\config\logging.yaml ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\__init__.py ---
"""Shared utilities and schemas for microservices."""

__all__ = ["schemas", "utils"]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\__init__.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\schemas\events.py ---
from datetime import datetime
from typing import Literal, Optional

from pydantic import BaseModel

DocumentEventType = Literal[
    "document_uploaded",
    "document_preprocessed",
    "document_ocr_completed",
    "document_failed",
]


class DocumentEvent(BaseModel):
    event_type: DocumentEventType
    document_id: str
    owner_id: str
    timestamp: datetime
    payload: Optional[dict] = None

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\schemas\events.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\schemas\__init__.py ---

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\schemas\__init__.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\broker.py ---
from __future__ import annotations

from typing import Any, Optional

import httpx


class AsyncBrokerClient:
    def __init__(self, base_url: str, *, timeout: float = 10.0) -> None:
        self._client = httpx.AsyncClient(base_url=base_url, timeout=timeout)

    async def close(self) -> None:
        await self._client.aclose()

    async def enqueue(self, topic: str, payload: dict[str, Any]) -> str:
        response = await self._client.post(f"/api/enqueue/{topic}", json=payload)
        response.raise_for_status()
        return response.json()["id"]

    async def claim(self, topic: str) -> Optional[dict[str, Any]]:
        response = await self._client.post(f"/api/claim/{topic}")
        if response.status_code == 404:
            return None
        response.raise_for_status()
        return response.json()

    async def ack(self, item_id: str) -> None:
        response = await self._client.post(f"/api/ack/{item_id}")
        response.raise_for_status()

    async def fail(self, item_id: str) -> None:
        response = await self._client.post(f"/api/fail/{item_id}")
        response.raise_for_status()

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\broker.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\jwt.py ---
from __future__ import annotations

from datetime import datetime, timedelta, timezone
from typing import Any

from jose import JWTError, jwt


def create_token(
    *,
    subject: str,
    secret_key: str,
    algorithm: str,
    ttl_seconds: int,
    scope: str,
    extra_claims: dict[str, Any] | None = None,
) -> str:
    now = datetime.now(timezone.utc)
    payload: dict[str, Any] = {
        "sub": subject,
        "iat": int(now.timestamp()),
        "exp": int((now + timedelta(seconds=ttl_seconds)).timestamp()),
        "scope": scope,
    }
    if extra_claims:
        payload.update(extra_claims)
    return jwt.encode(payload, secret_key, algorithm=algorithm)


def decode_token(*, token: str, secret_key: str, algorithm: str) -> dict[str, Any]:
    try:
        return jwt.decode(token, secret_key, algorithms=[algorithm])
    except JWTError as exc:
        raise ValueError("invalid token") from exc

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\jwt.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\logging.py ---
import logging
from typing import Optional


def configure_logging(level: Optional[int] = None) -> None:
    logging.basicConfig(
        level=level or logging.INFO,
        format="%(asctime)s %(levelname)s [%(name)s] %(message)s",
    )

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\logging.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\messaging.py ---
import json
from typing import Any


def serialize_payload(payload: dict[str, Any]) -> str:
    return json.dumps(payload, separators=(",", ":"))


def deserialize_payload(raw: str) -> dict[str, Any]:
    return json.loads(raw)

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\messaging.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\security.py ---
from __future__ import annotations

from passlib.context import CryptContext


_pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")


def hash_secret(raw: str) -> str:
    return _pwd_context.hash(raw)


def verify_secret(raw: str, hashed: str) -> bool:
    return _pwd_context.verify(raw, hashed)

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\security.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\__init__.py ---
"""Utility helpers shared across services."""

__all__ = [
    "broker",
    "jwt",
    "logging",
    "messaging",
    "security",
]

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\shared\python\utils\__init__.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\tests\gateway\test_gateway.py ---
def test_placeholder() -> None:
    assert True

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\tests\gateway\test_gateway.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\tests\processing\test_ocr_flow.py ---
def test_placeholder() -> None:
    assert True

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\tests\processing\test_ocr_flow.py ---


--- Start of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\tests\services\test_user_service.py ---
def test_placeholder() -> None:
    assert True

--- End of D:\Disk D 13-09-25\Universitate\Master\Anul2\sem1\MSOP\tests\services\test_user_service.py ---


